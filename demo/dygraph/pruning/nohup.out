WARNING 2021-02-03 02:58:22,016 launch.py:316] Not found distinct arguments and compiled with cuda. Default use collective mode
INFO 2021-02-03 02:58:22,016 launch_utils.py:582] Change selected_gpus into reletive values. --ips:0,1,2,3 will change into relative_ips:[0, 1, 2, 3] according to your CUDA_VISIBLE_DEVICES:['0', '1', '2', '3', '4', '5', '6', '7']
INFO 2021-02-03 02:58:22,017 launch_utils.py:471] Local start 4 processes. First process distributed environment info (Only For Debug): 
    +=======================================================================================+
    |                        Distributed Envs                      Value                    |
    +---------------------------------------------------------------------------------------+
    |                       PADDLE_TRAINER_ID                        0                      |
    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:57017               |
    |                     PADDLE_TRAINERS_NUM                        4                      |
    |                PADDLE_TRAINER_ENDPOINTS  ... 0.1:54970,127.0.0.1:32876,127.0.0.1:58949|
    |                     FLAGS_selected_gpus                        0                      |
    +=======================================================================================+

INFO 2021-02-03 02:58:22,017 launch_utils.py:475] details abouts PADDLE_TRAINER_ENDPOINTS can be found in hrank_resnet34_f-42_025_train_log/endpoints.log, and detail running logs maybe found in hrank_resnet34_f-42_025_train_log/workerlog.0
INFO 2021-02-03 02:58:28,091 launch_utils.py:307] terminate all the procs
ERROR 2021-02-03 02:58:28,091 launch_utils.py:545] ABORT!!! Out of all 4 trainers, the trainer process with rank=[0, 1, 2, 3] was aborted. Please check its log.
INFO 2021-02-03 02:58:31,095 launch_utils.py:307] terminate all the procs
-----------  Configuration Arguments -----------
gpus: 0,1,2,3
heter_worker_num: None
heter_workers: 
http_port: None
ips: 127.0.0.1
log_dir: hrank_resnet34_f-42_025_train_log
nproc_per_node: None
server_num: None
servers: 
training_script: new_train.py
training_script_args: ['--model=resnet34', '--data=imagenet', '--pruned_ratio=0.25', '--num_epochs=120', '--lr_strategy=cosine_decay', '--model_path=./hrank_resnet34_025_120_models']
worker_num: None
workers: 
------------------------------------------------
launch train in GPU mode
Traceback (most recent call last):
  File "new_train.py", line 14, in <module>
    import paddleslim
ModuleNotFoundError: No module named 'paddleslim'
WARNING 2021-02-03 02:59:08,017 launch.py:316] Not found distinct arguments and compiled with cuda. Default use collective mode
INFO 2021-02-03 02:59:08,018 launch_utils.py:582] Change selected_gpus into reletive values. --ips:0,1,2,3 will change into relative_ips:[0, 1, 2, 3] according to your CUDA_VISIBLE_DEVICES:['0', '1', '2', '3', '4', '5', '6', '7']
INFO 2021-02-03 02:59:08,019 launch_utils.py:471] Local start 4 processes. First process distributed environment info (Only For Debug): 
    +=======================================================================================+
    |                        Distributed Envs                      Value                    |
    +---------------------------------------------------------------------------------------+
    |                       PADDLE_TRAINER_ID                        0                      |
    |                 PADDLE_CURRENT_ENDPOINT                 127.0.0.1:52632               |
    |                     PADDLE_TRAINERS_NUM                        4                      |
    |                PADDLE_TRAINER_ENDPOINTS  ... 0.1:60434,127.0.0.1:57643,127.0.0.1:59643|
    |                     FLAGS_selected_gpus                        0                      |
    +=======================================================================================+

INFO 2021-02-03 02:59:08,019 launch_utils.py:475] details abouts PADDLE_TRAINER_ENDPOINTS can be found in hrank_resnet34_f-42_025_train_log/endpoints.log, and detail running logs maybe found in hrank_resnet34_f-42_025_train_log/workerlog.0
-----------  Configuration Arguments -----------
gpus: 0,1,2,3
heter_worker_num: None
heter_workers: 
http_port: None
ips: 127.0.0.1
log_dir: hrank_resnet34_f-42_025_train_log
nproc_per_node: None
server_num: None
servers: 
training_script: new_train.py
training_script_args: ['--model=resnet34', '--data=imagenet', '--pruned_ratio=0.25', '--num_epochs=120', '--lr_strategy=cosine_decay', '--model_path=./hrank_resnet34_025_120_models']
worker_num: None
workers: 
------------------------------------------------
launch train in GPU mode
/usr/local/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  from collections import Iterable, Mapping
/usr/local/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  from collections import Sized
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:188: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:485: DeprecationWarning: invalid escape sequence \s
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:879: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:1170: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:188: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:485: DeprecationWarning: invalid escape sequence \s
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:879: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddleslim-1.0.0-py3.7.egg/paddleslim/nas/ofa/layers.py:1170: DeprecationWarning: invalid escape sequence \_
/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py:156: UserWarning: PaddlePaddle version 1.8.4 or higher is required, but 0.0.0 installed, Maybe you are using a develop version, please make sure the version is good with your code.
  (min_version, fluid_version.full_version))
-----------  Configuration Arguments -----------
batch_size: 256
checkpoint: None
criterion: l1_norm
data: imagenet
l2_decay: 3e-05
log_period: 10
lr: 0.1
lr_strategy: cosine_decay
model: resnet34
model_path: ./hrank_resnet34_025_120_models
momentum_rate: 0.9
num_epochs: 120
pruned_ratio: 0.25
step_epochs: [30, 60, 90]
test_period: 10
use_gpu: True
------------------------------------------------
W0203 02:59:23.607076   728 device_context.cc:353] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.0
W0203 02:59:23.615707   728 device_context.cc:363] device: 0, cuDNN Version: 7.5.

  0%|          | 0/128669 [00:00<?, ?it/s]
  5%|▌         | 6702/128669 [00:00<00:01, 67019.74it/s]
 11%|█         | 14250/128669 [00:00<00:01, 71993.17it/s]
 17%|█▋        | 21804/128669 [00:00<00:01, 73612.24it/s]
 23%|██▎       | 29305/128669 [00:00<00:01, 74160.31it/s]
 29%|██▊       | 36780/128669 [00:00<00:01, 74372.07it/s]
 34%|███▍      | 44218/128669 [00:00<00:01, 69008.70it/s]
 40%|████      | 51846/128669 [00:00<00:01, 71267.49it/s]
 46%|████▌     | 59391/128669 [00:00<00:00, 72551.65it/s]
 52%|█████▏    | 66938/128669 [00:00<00:00, 73440.52it/s]
 58%|█████▊    | 74475/128669 [00:01<00:00, 74024.18it/s]
 64%|██████▎   | 82010/128669 [00:01<00:00, 74424.16it/s]
 70%|██████▉   | 89553/128669 [00:01<00:00, 74724.55it/s]
 75%|███████▌  | 97089/128669 [00:01<00:00, 74910.11it/s]
 81%|████████▏ | 104589/128669 [00:01<00:00, 74863.61it/s]
 87%|████████▋ | 112082/128669 [00:01<00:00, 74773.75it/s]
 93%|█████████▎| 119649/128669 [00:01<00:00, 75040.99it/s]
 99%|█████████▉| 127220/128669 [00:01<00:00, 75240.99it/s]
100%|██████████| 128669/128669 [00:01<00:00, 73785.74it/s]
/usr/local/lib/python3.7/site-packages/paddle/nn/layer/norm.py:648: UserWarning: When training, we now always track global mean and variance.
  "When training, we now always track global mean and variance.")
2021-02-03 02:59:32,437-INFO: FLOPs before pruning: 3672356.864GFLOPs
2021-02-03 02:59:33,773-INFO: Found 20 groups.
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
data shape:(1, 3, 224, 224)
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [55688, 55657, 55721, 55725, 55635, 55707, 55719, 55656, 55568, 55684, 55744, 55684, 55620, 55712, 55753, 779  , 805  , 55696, 55706, 55677, 55688, 55754, 55616, 55555, 55570, 55570, 55759, 55686, 55775, 55742, 55645, 39267, 55687, 55690, 55256, 2215 , 55498, 55666, 55603, 55742, 55729, 0    , 55702, 55695, 55720, 55593, 806  , 12452, 55576, 2144 , 55682, 55651, 55678, 55752, 55741, 55481, 55737, 19689, 55700, 55667, 55530, 55734, 55663, 0    ])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27815, 27840, 27833, 27780, 27812, 27854, 27611, 27818, 27803, 27786, 27883, 27762, 27821, 27668, 27811, 27771, 27733, 27755, 27810, 27837, 27782, 27790, 27839, 27755, 27880, 27707, 27780, 27820, 27797, 27873, 27720, 27832, 27814, 27838, 27865, 27846, 27632, 27859, 27801, 27816, 27842, 27825, 27811, 27806, 27855, 27841, 27836, 27851, 27875, 27829, 27770, 27662, 27812, 27837, 27837, 27811, 27667, 27821, 27688, 27806, 27872, 27831, 27809, 27841])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27825, 27599, 27851, 27657, 27692, 27562, 27784, 27249, 27518, 27434, 27486, 27681, 27479, 27843, 27600, 27595, 27749, 27577, 27867, 27525, 27667, 27844, 27686, 27482, 27244, 27757, 27713, 27733, 27734, 27565, 27612, 27621, 27635, 27765, 27641, 27742, 27558, 27714, 27638, 27516, 27723, 27829, 27635, 27676, 27849, 27588, 27753, 27750, 27648, 27424, 27531, 27618, 27860, 27691, 27565, 27522, 27813, 27459, 27673, 27500, 27809, 27539, 27892, 27676])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27904, 27921, 27937, 27758, 27866, 27833, 27898, 27851, 27913, 27934, 27906, 27896, 27887, 27871, 27914, 27871, 27929, 27903, 27827, 27862, 27903, 27884, 27903, 27839, 27893, 27922, 27886, 27871, 27931, 27881, 27927, 27881, 27750, 27924, 27887, 27912, 27922, 27891, 27935, 27924, 27919, 27872, 27917, 27845, 27931, 27864, 27933, 27868, 27907, 27909, 27878, 27854, 27931, 27893, 27905, 27877, 27911, 27793, 27903, 27831, 27913, 27902, 27928, 27881])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27901, 27662, 27839, 27700, 27808, 27662, 27877, 27659, 27608, 27603, 27631, 27763, 27587, 27905, 27644, 27774, 27877, 27753, 27906, 27781, 27647, 27885, 27888, 27827, 27597, 27857, 27743, 27694, 27840, 27701, 27633, 27763, 27802, 27877, 27672, 27740, 27596, 27757, 27678, 27658, 27812, 27872, 27758, 27630, 27915, 27818, 27821, 27832, 27838, 27636, 27742, 27719, 27879, 27671, 27612, 27631, 27880, 27636, 27719, 27678, 27867, 27545, 27926, 27719])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27958, 27945, 27891, 27831, 27955, 27931, 27947, 27959, 27963, 27956, 27955, 27925, 27942, 27947, 27962, 27953, 27932, 27951, 27939, 27959, 27952, 27949, 27931, 27945, 27953, 27922, 27947, 27959, 27948, 27945, 27927, 27940, 27934, 27957, 27962, 27956, 27952, 27955, 27949, 27956, 27954, 27955, 27959, 27922, 27939, 27937, 27955, 27953, 27865, 27951, 27897, 27959, 27909, 27961, 27952, 27955, 27957, 27940, 27961, 27948, 27949, 27941, 27948, 27925])
Tensor(shape=[64], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [27913, 27790, 27899, 27873, 27827, 27830, 27900, 27763, 27767, 27736, 27831, 27883, 27738, 27905, 27823, 27830, 27911, 27871, 27903, 27796, 27773, 27908, 27883, 27891, 27752, 27906, 27888, 27793, 27879, 27826, 27820, 27814, 27861, 27917, 27817, 27776, 27770, 27901, 27773, 27803, 27886, 27899, 27863, 27807, 27912, 27865, 27866, 27908, 27869, 27765, 27801, 27835, 27903, 27863, 27779, 27752, 27887, 27761, 27808, 27833, 27915, 27820, 27915, 27805])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13985, 13982, 13986, 13989, 13989, 13990, 13984, 13985, 13983, 13987, 13987, 13985, 13987, 13986, 13982, 13985, 13989, 13978, 13987, 13989, 13982, 13987, 13984, 13988, 13985, 13989, 13984, 13988, 13988, 13986, 13984, 13988, 13989, 13985, 13986, 13980, 13983, 13982, 13986, 13989, 13983, 13984, 13986, 13988, 13990, 13982, 13984, 13981, 13988, 13985, 13989, 13978, 13985, 13986, 13989, 13988, 13983, 13981, 13989, 13987, 13987, 13984, 13985, 13984, 13986, 13990, 13982, 13987, 13984, 13987, 13985, 13983, 13988, 13987, 13976, 13983, 13987, 13991, 13986, 13988, 13988, 13984, 13986, 13985, 13989, 13988, 13989, 13985, 13982, 13980, 13968, 13986, 13984, 13977, 13988, 13988, 13986, 13984, 13989, 13987, 13989, 13990, 13987, 13984, 13986, 13984, 13982, 13986, 13989, 13989, 13984, 13986, 13989, 13986, 13987, 13986, 13988, 13982, 13986, 13986, 13984, 13988, 13986, 13982, 13985, 13984, 13984, 13981])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13963, 13926, 13966, 13956, 13974, 13972, 13966, 13956, 13950, 13976, 13975, 13956, 13969, 13965, 13968, 13971, 13972, 13970, 13948, 13929, 13963, 13954, 13972, 13946, 13963, 13968, 13977, 13958, 13967, 13966, 13966, 13954, 13969, 13961, 13967, 13953, 13972, 13978, 13969, 13948, 13970, 13965, 13946, 13959, 13945, 13949, 13973, 13970, 13971, 13954, 13959, 13968, 13957, 13927, 13978, 13970, 13946, 13971, 13956, 13940, 13947, 13974, 13971, 13966, 13964, 13974, 13950, 13963, 13942, 13968, 13969, 13969, 13962, 13976, 13970, 13961, 13937, 13959, 13927, 13960, 13947, 13970, 13973, 13975, 13974, 13959, 13963, 13940, 13959, 13974, 13952, 13967, 13969, 13972, 13965, 13961, 13953, 13963, 13964, 13961, 13963, 13965, 13971, 13964, 13972, 13971, 13968, 13957, 13948, 13968, 13974, 13924, 13959, 13969, 13958, 13970, 13933, 13957, 13965, 13976, 13966, 13965, 13971, 13970, 13969, 13966, 13948, 13974])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13967, 13959, 13975, 13960, 13972, 13975, 13977, 13955, 13959, 13961, 13969, 13981, 13971, 13978, 13979, 13963, 13967, 13968, 13971, 13957, 13965, 13958, 13973, 13963, 13980, 13969, 13970, 13971, 13961, 13970, 13972, 13966, 13977, 13975, 13962, 13945, 13940, 13976, 13968, 13963, 13967, 13978, 13962, 13957, 13956, 13970, 13969, 13976, 13963, 13958, 13967, 13976, 13978, 13971, 13966, 13973, 13963, 13971, 13973, 13961, 13954, 13950, 13957, 13979, 13966, 13978, 13957, 13945, 13978, 13955, 13976, 13976, 13965, 13975, 13970, 13960, 13972, 13966, 13974, 13968, 13949, 13983, 13981, 13962, 13964, 13969, 13955, 13967, 13972, 13964, 13968, 13964, 13975, 13972, 13946, 13966, 13926, 13978, 13920, 13962, 13954, 13973, 13972, 13952, 13971, 13968, 13963, 13967, 13963, 13974, 13969, 13961, 13965, 13963, 13948, 13975, 13961, 13955, 13962, 13968, 13970, 13974, 13977, 13972, 13970, 13979, 13967, 13961])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13975, 13966, 13974, 13971, 13979, 13980, 13980, 13976, 13973, 13977, 13982, 13983, 13979, 13977, 13973, 13975, 13966, 13977, 13975, 13982, 13980, 13972, 13965, 13970, 13973, 13984, 13974, 13966, 13961, 13973, 13978, 13972, 13983, 13978, 13974, 13977, 13974, 13966, 13973, 13972, 13977, 13969, 13974, 13970, 13974, 13977, 13966, 13974, 13964, 13984, 13980, 13979, 13982, 13972, 13970, 13972, 13973, 13983, 13973, 13976, 13975, 13970, 13977, 13964, 13981, 13969, 13974, 13973, 13972, 13968, 13971, 13971, 13978, 13968, 13965, 13979, 13973, 13977, 13972, 13974, 13957, 13969, 13972, 13966, 13974, 13970, 13978, 13980, 13981, 13970, 13980, 13964, 13969, 13966, 13970, 13972, 13966, 13984, 13958, 13980, 13975, 13972, 13973, 13980, 13977, 13968, 13978, 13972, 13973, 13980, 13980, 13971, 13967, 13970, 13964, 13957, 13982, 13982, 13971, 13979, 13973, 13977, 13967, 13974, 13969, 13978, 13969, 13980])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13889, 13908, 13946, 13893, 13873, 13912, 13908, 13903, 13900, 13915, 13825, 13908, 13862, 13938, 13871, 13900, 13862, 13923, 13916, 13902, 13879, 13923, 13887, 13910, 13931, 13915, 13880, 13853, 13939, 13891, 13855, 13868, 13911, 13891, 13878, 13928, 13908, 13906, 13915, 13910, 13884, 13870, 13902, 13875, 13941, 13927, 13899, 13921, 13925, 13894, 13893, 13900, 13913, 13955, 13883, 13929, 13893, 13904, 13908, 13914, 13905, 13835, 13904, 13862, 13879, 13908, 13918, 13914, 13916, 13919, 13838, 13914, 13909, 13848, 13814, 13884, 13958, 13953, 13944, 13888, 13900, 13885, 13887, 13934, 13892, 13909, 13897, 13943, 13888, 13922, 13933, 13898, 13875, 13876, 13861, 13715, 13862, 13856, 13873, 13849, 13854, 13938, 13921, 13909, 13905, 13869, 13871, 13914, 13894, 13891, 13856, 13909, 13878, 13883, 13880, 13911, 13904, 13727, 13918, 13837, 13871, 13869, 13837, 13913, 13892, 13905, 13906, 13887])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13981, 13979, 13991, 13979, 13975, 13979, 13986, 13973, 13992, 13982, 13984, 13981, 13971, 13981, 13983, 13981, 13987, 13974, 13978, 13978, 13973, 13986, 13973, 13974, 13982, 13970, 13984, 13979, 13977, 13979, 13980, 13976, 13977, 13979, 13981, 13983, 13974, 13979, 13984, 13980, 13976, 13973, 13983, 13984, 13977, 13978, 13982, 13988, 13982, 13987, 13976, 13986, 13971, 13976, 13982, 13983, 13977, 13986, 13974, 13980, 13990, 13966, 13972, 13986, 13973, 13978, 13981, 13973, 13966, 13975, 13974, 13977, 13984, 13984, 13988, 13980, 13980, 13984, 13984, 13974, 13976, 13991, 13984, 13971, 13977, 13972, 13976, 13978, 13972, 13973, 13971, 13981, 13984, 13966, 13986, 13969, 13981, 13986, 13975, 13960, 13982, 13975, 13978, 13982, 13977, 13978, 13980, 13975, 13970, 13982, 13985, 13968, 13974, 13973, 13971, 13980, 13988, 13982, 13980, 13975, 13979, 13975, 13980, 13976, 13989, 13976, 13976, 13984])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13938, 13900, 13935, 13938, 13910, 13947, 13904, 13920, 13909, 13938, 13927, 13891, 13887, 13913, 13898, 13933, 13923, 13936, 13890, 13898, 13939, 13926, 13920, 13903, 13932, 13925, 13906, 13913, 13941, 13905, 13886, 13907, 13913, 13882, 13909, 13903, 13901, 13906, 13921, 13918, 13928, 13918, 13888, 13903, 13953, 13940, 13941, 13920, 13948, 13922, 13949, 13905, 13925, 13938, 13906, 13908, 13940, 13929, 13871, 13910, 13921, 13898, 13925, 13899, 13923, 13917, 13892, 13926, 13909, 13937, 13910, 13930, 13916, 13920, 13903, 13907, 13936, 13922, 13921, 13933, 13903, 13924, 13890, 13932, 13927, 13928, 13942, 13928, 13937, 13937, 13919, 13921, 13926, 13918, 13918, 13912, 13928, 13923, 13938, 13875, 13909, 13920, 13934, 13943, 13892, 13912, 13891, 13929, 13902, 13883, 13923, 13910, 13930, 13915, 13959, 13950, 13880, 13898, 13929, 13914, 13909, 13920, 13921, 13954, 13916, 13911, 13914, 13918])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13977, 13969, 13980, 13985, 13986, 13983, 13979, 13992, 13981, 13986, 13991, 13988, 13988, 13970, 13969, 13982, 13992, 13980, 13987, 13966, 13976, 13986, 13985, 13988, 13980, 13985, 13990, 13983, 13983, 13976, 13980, 13988, 13990, 13980, 13992, 13987, 13984, 13973, 13979, 13978, 13991, 13977, 13968, 13990, 13980, 13982, 13985, 13983, 13986, 13979, 13974, 13982, 13988, 13986, 13983, 13978, 13978, 13984, 13986, 13989, 13983, 13985, 13985, 13981, 13985, 13989, 13977, 13978, 13985, 13985, 13988, 13988, 13987, 13986, 13988, 13983, 13981, 13980, 13984, 13978, 13979, 13979, 13982, 13989, 13974, 13981, 13986, 13993, 13985, 13985, 13982, 13987, 13982, 13983, 13978, 13975, 13977, 13983, 13993, 13985, 13987, 13985, 13983, 13986, 13987, 13987, 13983, 13984, 13981, 13981, 13974, 13989, 13988, 13975, 13985, 13981, 13988, 13976, 13981, 13990, 13977, 13975, 13979, 13979, 13983, 13981, 13987, 13977])
Tensor(shape=[128], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [13912, 13815, 13923, 13926, 13925, 13931, 13899, 13899, 13824, 13943, 13901, 13869, 13871, 13883, 13900, 13927, 13851, 13929, 13864, 13890, 13944, 13919, 13940, 13842, 13896, 13922, 13904, 13909, 13905, 13877, 13901, 13869, 13883, 13881, 13910, 13839, 13941, 13908, 13929, 13894, 13931, 13920, 13871, 13886, 13947, 13900, 13929, 13919, 13936, 13905, 13945, 13935, 13901, 13906, 13924, 13918, 13921, 13931, 13842, 13833, 13845, 13901, 13922, 13890, 13906, 13914, 13819, 13929, 13865, 13941, 13906, 13914, 13909, 13867, 13911, 13889, 13862, 13877, 13867, 13901, 13906, 13897, 13919, 13924, 13931, 13905, 13938, 13895, 13925, 13940, 13846, 13911, 13915, 13924, 13907, 13906, 13911, 13918, 13898, 13910, 13917, 13901, 13923, 13925, 13825, 13908, 13885, 13910, 13851, 13928, 13905, 13835, 13885, 13881, 13911, 13917, 13819, 13877, 13907, 13884, 13914, 13889, 13914, 13938, 13907, 13920, 13906, 13895])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6993, 6993, 6994, 6995, 6996, 6992, 6992, 6995, 6997, 6992, 6994, 6996, 6990, 6994, 6991, 6991, 6993, 6995, 6995, 6995, 6995, 6989, 6992, 6994, 6995, 6997, 6995, 6995, 6994, 6992, 6990, 6992, 6991, 6993, 6994, 6991, 6994, 6991, 6992, 6995, 6990, 6993, 6994, 6992, 6994, 6995, 6995, 6995, 6992, 6988, 6991, 6996, 6990, 6991, 6990, 6989, 6990, 6995, 6994, 6996, 6990, 6992, 6992, 6990, 6992, 6989, 6993, 6994, 6997, 6990, 6996, 6993, 6992, 6992, 6990, 6990, 6993, 6995, 6991, 6994, 6995, 6992, 6994, 6996, 6995, 6994, 6993, 6992, 6994, 6996, 6997, 6987, 6995, 6994, 6991, 6997, 6994, 6991, 6990, 6990, 6996, 6992, 6998, 6993, 6994, 6999, 6988, 6996, 6986, 6991, 6998, 6995, 6990, 6994, 6992, 6992, 6992, 6993, 6991, 6994, 6991, 6994, 6990, 6991, 6995, 6994, 6990, 6992, 6997, 6995, 6993, 6992, 6994, 6991, 6991, 6991, 6993, 6994, 6989, 6990, 6990, 6991, 6990, 6990, 6994, 6992, 6994, 6992, 6993, 6991, 6993, 6996, 6991, 6994, 6997, 6996, 6991, 6996, 6996, 6991, 6990, 6990, 6996, 6994, 6995, 6992, 6994, 6997, 6990, 6995, 6991, 6995, 6987, 6996, 6993, 6993, 6995, 6994, 6994, 6996, 6993, 6994, 6997, 6992, 6993, 6993, 6997, 6993, 6992, 6990, 6990, 6988, 6995, 6990, 6997, 6992, 6989, 6990, 6992, 6998, 6994, 6990, 6991, 6989, 6997, 6993, 6994, 6990, 6997, 6992, 6992, 6986, 6994, 6994, 6989, 6994, 6993, 6995, 6996, 6993, 6990, 6996, 6990, 6991, 6996, 6996, 6991, 6987, 6993, 6997, 6990, 6995, 6995, 6994, 6993, 6993, 6993, 6992, 6997, 6995, 6994, 6992, 6992, 6995, 6993, 6994, 6989, 6991, 6989, 6995, 6989, 6995, 6996, 6990, 6993, 6994])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6990, 6984, 6975, 6966, 6983, 6983, 6981, 6984, 6985, 6980, 6982, 6981, 6986, 6981, 6971, 6980, 6988, 6974, 6982, 6982, 6987, 6976, 6978, 6988, 6972, 6973, 6976, 6986, 6963, 6977, 6982, 6985, 6982, 6977, 6984, 6975, 6979, 6985, 6976, 6977, 6978, 6981, 6973, 6978, 6981, 6977, 6980, 6976, 6966, 6986, 6977, 6985, 6978, 6977, 6976, 6977, 6986, 6982, 6986, 6985, 6973, 6985, 6972, 6973, 6988, 6976, 6980, 6982, 6981, 6977, 6981, 6979, 6984, 6985, 6986, 6976, 6980, 6984, 6977, 6980, 6982, 6976, 6976, 6977, 6963, 6984, 6981, 6985, 6977, 6983, 6981, 6973, 6982, 6978, 6982, 6979, 6987, 6981, 6986, 6980, 6984, 6975, 6981, 6977, 6980, 6982, 6981, 6982, 6973, 6982, 6980, 6978, 6981, 6975, 6979, 6986, 6972, 6983, 6968, 6975, 6974, 6969, 6975, 6986, 6982, 6967, 6979, 6978, 6984, 6983, 6976, 6979, 6978, 6980, 6983, 6982, 6986, 6993, 6962, 6971, 6985, 6979, 6983, 6977, 6967, 6990, 6971, 6988, 6991, 6971, 6975, 6975, 6979, 6985, 6980, 6981, 6973, 6976, 6978, 6978, 6985, 6979, 6978, 6977, 6980, 6990, 6977, 6982, 6980, 6985, 6990, 6984, 6979, 6975, 6991, 6983, 6980, 6973, 6991, 6975, 6972, 6976, 6975, 6987, 6993, 6986, 6979, 6983, 6975, 6981, 6985, 6982, 6984, 6984, 6976, 6985, 6988, 6977, 6977, 6979, 6977, 6985, 6974, 6976, 6980, 6983, 6980, 6972, 6975, 6980, 6983, 6989, 6981, 6966, 6977, 6987, 6971, 6983, 6990, 6975, 6984, 6987, 6982, 6986, 6978, 6971, 6978, 6981, 6979, 6984, 6980, 6969, 6983, 6983, 6983, 6971, 6970, 6985, 6988, 6976, 6971, 6971, 6984, 6990, 6982, 6987, 6977, 6976, 6978, 6973, 6984, 6980, 6970, 6980, 6991, 6969])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6982, 6975, 6981, 6986, 6979, 6988, 6982, 6991, 6982, 6985, 6974, 6983, 6979, 6984, 6985, 6985, 6982, 6984, 6991, 6984, 6991, 6984, 6969, 6988, 6972, 6984, 6986, 6979, 6971, 6986, 6988, 6981, 6977, 6971, 6982, 6989, 6969, 6981, 6983, 6987, 6983, 6964, 6989, 6978, 6980, 6987, 6982, 6978, 6981, 6988, 6981, 6988, 6979, 6991, 6984, 6981, 6985, 6989, 6960, 6987, 6965, 6987, 6967, 6987, 6981, 6980, 6979, 6982, 6970, 6981, 6982, 6993, 6985, 6988, 6980, 6987, 6987, 6981, 6976, 6977, 6985, 6984, 6974, 6988, 6970, 6992, 6987, 6976, 6983, 6984, 6978, 6981, 6985, 6986, 6984, 6988, 6995, 6984, 6976, 6974, 6978, 6977, 6973, 6982, 6969, 6974, 6980, 6987, 6981, 6983, 6977, 6978, 6981, 6980, 6975, 6981, 6982, 6981, 6984, 6982, 6991, 6960, 6980, 6982, 6983, 6976, 6980, 6977, 6967, 6985, 6988, 6982, 6980, 6978, 6982, 6978, 6979, 6988, 6989, 6976, 6979, 6988, 6983, 6975, 6981, 6977, 6980, 6983, 6981, 6969, 6983, 6988, 6988, 6985, 6963, 6990, 6980, 6988, 6983, 6963, 6985, 6979, 6972, 6981, 6970, 6987, 6978, 6984, 6975, 6988, 6978, 6987, 6983, 6973, 6981, 6983, 6984, 6989, 6983, 6983, 6977, 6975, 6973, 6984, 6989, 6976, 6976, 6977, 6981, 6989, 6984, 6989, 6982, 6970, 6990, 6952, 6980, 6976, 6980, 6966, 6976, 6993, 6981, 6988, 6988, 6976, 6993, 6973, 6989, 6975, 6988, 6977, 6981, 6987, 6991, 6980, 6971, 6990, 6986, 6973, 6986, 6966, 6980, 6986, 6974, 6992, 6989, 6972, 6985, 6971, 6984, 6969, 6986, 6989, 6986, 6981, 6978, 6983, 6974, 6989, 6989, 6960, 6980, 6962, 6989, 6984, 6979, 6983, 6982, 6978, 6972, 6982, 6986, 6984, 6996, 6980])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6975, 6985, 6988, 6971, 6989, 6985, 6982, 6983, 6985, 6992, 6975, 6993, 6979, 6986, 6978, 6985, 6983, 6989, 6975, 6971, 6977, 6979, 6989, 6991, 6982, 6985, 6984, 6982, 6984, 6983, 6983, 6988, 6989, 6974, 6986, 6987, 6962, 6982, 6990, 6984, 6974, 6982, 6982, 6982, 6969, 6987, 6983, 6990, 6975, 6979, 6979, 6984, 6982, 6986, 6979, 6971, 6978, 6989, 6981, 6979, 6984, 6973, 6979, 6989, 6982, 6974, 6980, 6989, 6972, 6981, 6969, 6980, 6984, 6975, 6978, 6992, 6984, 6987, 6981, 6983, 6978, 6986, 6977, 6974, 6974, 6990, 6979, 6984, 6981, 6981, 6982, 6970, 6981, 6993, 6982, 6985, 6981, 6975, 6979, 6975, 6984, 6986, 6991, 6986, 6975, 6992, 6989, 6983, 6984, 6982, 6977, 6975, 6977, 6987, 6988, 6981, 6990, 6986, 6978, 6980, 6984, 6975, 6981, 6983, 6989, 6993, 6979, 6966, 6981, 6970, 6980, 6975, 6973, 6981, 6986, 6977, 6981, 6981, 6979, 6979, 6979, 6990, 6973, 6973, 6988, 6989, 6979, 6985, 6982, 6989, 6977, 6984, 6974, 6967, 6990, 6972, 6981, 6964, 6966, 6976, 6981, 6970, 6990, 6981, 6983, 6978, 6971, 6989, 6983, 6982, 6981, 6986, 6972, 6974, 6989, 6989, 6983, 6982, 6985, 6974, 6981, 6986, 6976, 6980, 6972, 6982, 6984, 6976, 6989, 6971, 6974, 6990, 6966, 6973, 6981, 6986, 6976, 6983, 6991, 6978, 6977, 6979, 6981, 6985, 6970, 6985, 6978, 6976, 6978, 6973, 6975, 6980, 6973, 6987, 6986, 6979, 6984, 6975, 6978, 6985, 6988, 6985, 6984, 6980, 6973, 6990, 6992, 6985, 6980, 6980, 6978, 6989, 6972, 6988, 6985, 6990, 6961, 6972, 6992, 6977, 6976, 6983, 6974, 6983, 6981, 6980, 6971, 6992, 6980, 6978, 6975, 6988, 6983, 6979, 6975, 6979])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6933, 6921, 6887, 6899, 6936, 6895, 6921, 6909, 6903, 6911, 6918, 6906, 6934, 6881, 6893, 6911, 6909, 6891, 6924, 6906, 6926, 6906, 6907, 6909, 6922, 6923, 6926, 6939, 6895, 6914, 6921, 6913, 6942, 6911, 6912, 6893, 6916, 6924, 6863, 6902, 6922, 6912, 6879, 6926, 6901, 6920, 6919, 6896, 6923, 6898, 6893, 6896, 6932, 6920, 6907, 6905, 6918, 6895, 6914, 6937, 6899, 6921, 6929, 6923, 6934, 6915, 6920, 6919, 6940, 6934, 6925, 6878, 6894, 6900, 6913, 6926, 6916, 6923, 6904, 6974, 6941, 6942, 6923, 6891, 6893, 6911, 6902, 6934, 6920, 6937, 6931, 6867, 6912, 6896, 6891, 6925, 6923, 6908, 6910, 6908, 6906, 6913, 6941, 6914, 6934, 6939, 6939, 6872, 6901, 6938, 6939, 6872, 6931, 6920, 6877, 6901, 6880, 6929, 6900, 6919, 6893, 6921, 6904, 6914, 6907, 6854, 6944, 6923, 6905, 6914, 6915, 6915, 6913, 6901, 6913, 6924, 6908, 6944, 6893, 6903, 6903, 6900, 6941, 6929, 6928, 6940, 6878, 6938, 6926, 6921, 6915, 6872, 6897, 6915, 6929, 6944, 6904, 6903, 6928, 6913, 6920, 6916, 6900, 6902, 6924, 6939, 6928, 6897, 6917, 6913, 6928, 6907, 6909, 6915, 6934, 6919, 6910, 6928, 6902, 6919, 6908, 6942, 6911, 6920, 6933, 6896, 6911, 6930, 6901, 6886, 6922, 6928, 6887, 6936, 6905, 6898, 6922, 6886, 6916, 6971, 6913, 6905, 6931, 6910, 6892, 6879, 6932, 6953, 6889, 6940, 6889, 6901, 6917, 6898, 6909, 6935, 6947, 6905, 6880, 6886, 6924, 6926, 6898, 6934, 6909, 6907, 6894, 6913, 6902, 6918, 6923, 6906, 6901, 6912, 6949, 6892, 6888, 6914, 6937, 6908, 6925, 6931, 6890, 6924, 6936, 6951, 6918, 6913, 6894, 6902, 6912, 6905, 6887, 6920, 6917, 6883])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6988, 6977, 6985, 6981, 6982, 6987, 6976, 6979, 6964, 6970, 6984, 6983, 6983, 6977, 6988, 6978, 6987, 6994, 6975, 6982, 6983, 6968, 6983, 6975, 6970, 6986, 6976, 6982, 6977, 6988, 6970, 6979, 6985, 6981, 6985, 6986, 6982, 6968, 6988, 6987, 6981, 6986, 6978, 6981, 6985, 6985, 6973, 6974, 6988, 6978, 6982, 6975, 6986, 6982, 6981, 6979, 6991, 6984, 6985, 6980, 6983, 6988, 6990, 6978, 6979, 6972, 6985, 6981, 6982, 6989, 6985, 6987, 6980, 6994, 6990, 6986, 6975, 6982, 6989, 6986, 6982, 6990, 6977, 6969, 6980, 6973, 6985, 6985, 6982, 6970, 6987, 6985, 6983, 6984, 6983, 6986, 6979, 6974, 6983, 6982, 6980, 6983, 6972, 6985, 6984, 6990, 6986, 6982, 6985, 6990, 6982, 6984, 6988, 6987, 6982, 6980, 6986, 6979, 6983, 6983, 6985, 6995, 6983, 6984, 6983, 6982, 6984, 6979, 6977, 6983, 6985, 6991, 6979, 6977, 6977, 6986, 6979, 6987, 6980, 6968, 6974, 6980, 6963, 6986, 6978, 6984, 6981, 6975, 6979, 6975, 6991, 6981, 6975, 6979, 6988, 6989, 6990, 6990, 6978, 6988, 6981, 6986, 6981, 6973, 6969, 6984, 6979, 6974, 6982, 6983, 6974, 6973, 6983, 6962, 6978, 6989, 6987, 6983, 6990, 6985, 6988, 6981, 6972, 6985, 6972, 6982, 6991, 6981, 6987, 6979, 6978, 6968, 6987, 6991, 6981, 6982, 6983, 6981, 6979, 6986, 6980, 6967, 6968, 6986, 6976, 6989, 6988, 6989, 6983, 6983, 6990, 6982, 6974, 6981, 6983, 6987, 6980, 6986, 6992, 6975, 6984, 6985, 6977, 6974, 6983, 6986, 6977, 6984, 6988, 6983, 6976, 6977, 6982, 6978, 6981, 6981, 6987, 6983, 6983, 6970, 6984, 6986, 6974, 6981, 6976, 6981, 6970, 6989, 6975, 6990, 6989, 6987, 6983, 6978, 6991, 6983])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6929, 6902, 6882, 6851, 6925, 6881, 6910, 6861, 6877, 6865, 6910, 6847, 6923, 6806, 6872, 6846, 6909, 6878, 6865, 6875, 6905, 6859, 6915, 6874, 6892, 6903, 6923, 6884, 6785, 6885, 6914, 6917, 6926, 6877, 6918, 6862, 6903, 6914, 6834, 6862, 6875, 6925, 6837, 6885, 6902, 6922, 6901, 6923, 6794, 6848, 6870, 6876, 6927, 6896, 6899, 6847, 6925, 6902, 6925, 6934, 6917, 6874, 6908, 6858, 6915, 6953, 6917, 6885, 6948, 6933, 6918, 6870, 6857, 6851, 6896, 6922, 6921, 6895, 6886, 6940, 6916, 6941, 6906, 6885, 6889, 6900, 6855, 6906, 6927, 6913, 6919, 6837, 6785, 6865, 6891, 6911, 6889, 6899, 6891, 6865, 6874, 6891, 6927, 6899, 6920, 6927, 6922, 6883, 6913, 6924, 6933, 6845, 6937, 6904, 6886, 6895, 6843, 6912, 6862, 6888, 6817, 6913, 6788, 6921, 6843, 6833, 6943, 6884, 6828, 6898, 6929, 6836, 6919, 6876, 6907, 6910, 6878, 6936, 6862, 6883, 6917, 6879, 6931, 6787, 6919, 6926, 6886, 6842, 6918, 6888, 6904, 6898, 6888, 6873, 6883, 6930, 6908, 6884, 6910, 6894, 6921, 6894, 6904, 6894, 6913, 6942, 6904, 6884, 6920, 6925, 6928, 6895, 6910, 6869, 6938, 6904, 6907, 6896, 6886, 6901, 6927, 6939, 6915, 6922, 6915, 6910, 6899, 6925, 6892, 6900, 6872, 6873, 6885, 6863, 6893, 6915, 6926, 6898, 6907, 6948, 6927, 6849, 6909, 6900, 6877, 6829, 6900, 6942, 6845, 6907, 6902, 6915, 6852, 6848, 6903, 6904, 6939, 6889, 6883, 6846, 6924, 6919, 6880, 6931, 6884, 6892, 6909, 6884, 6903, 6906, 6872, 6923, 6860, 6883, 6938, 6810, 6872, 6848, 6918, 6830, 6917, 6899, 6890, 6927, 6921, 6936, 6909, 6930, 6835, 6890, 6872, 6919, 6817, 6854, 6901, 6859])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6978, 6982, 6974, 6976, 6985, 6980, 6979, 6983, 6974, 6979, 6982, 6991, 6979, 6985, 6966, 6990, 6976, 6988, 6981, 6970, 6967, 6976, 6987, 6986, 6983, 6991, 6981, 6984, 6974, 6967, 6989, 6972, 6982, 6985, 6981, 6980, 6982, 6976, 6973, 6985, 6992, 6984, 6988, 6984, 6978, 6974, 6979, 6975, 6985, 6979, 6989, 6981, 6979, 6979, 6985, 6978, 6978, 6979, 6981, 6981, 6984, 6978, 6979, 6978, 6984, 6985, 6985, 6983, 6991, 6985, 6979, 6972, 6979, 6985, 6984, 6982, 6988, 6985, 6989, 6977, 6964, 6977, 6981, 6983, 6981, 6983, 6986, 6979, 6979, 6979, 6981, 6985, 6976, 6974, 6970, 6971, 6972, 6978, 6979, 6973, 6975, 6969, 6966, 6975, 6985, 6974, 6984, 6975, 6985, 6982, 6980, 6975, 6977, 6977, 6973, 6975, 6977, 6977, 6990, 6974, 6982, 6984, 6987, 6985, 6977, 6986, 6975, 6977, 6986, 6988, 6982, 6968, 6979, 6985, 6987, 6984, 6973, 6983, 6982, 6986, 6988, 6982, 6978, 6986, 6976, 6973, 6985, 6981, 6987, 6976, 6977, 6986, 6976, 6981, 6982, 6989, 6982, 6985, 6982, 6980, 6978, 6965, 6984, 6974, 6989, 6983, 6981, 6981, 6986, 6981, 6977, 6982, 6993, 6982, 6977, 6984, 6989, 6961, 6978, 6973, 6984, 6986, 6986, 6980, 6980, 6988, 6974, 6979, 6985, 6974, 6984, 6984, 6972, 6987, 6958, 6987, 6982, 6974, 6972, 6987, 6984, 6985, 6984, 6983, 6975, 6980, 6980, 6979, 6981, 6975, 6976, 6985, 6969, 6983, 6981, 6979, 6987, 6969, 6977, 6984, 6967, 6983, 6982, 6973, 6970, 6979, 6971, 6990, 6986, 6984, 6977, 6976, 6987, 6980, 6990, 6983, 6976, 6984, 6960, 6980, 6984, 6973, 6976, 6978, 6986, 6978, 6985, 6979, 6969, 6985, 6989, 6977, 6974, 6985, 6975, 6980])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6919, 6861, 6824, 6742, 6915, 6835, 6876, 6510, 6835, 6794, 6779, 6786, 6905, 6738, 6807, 6806, 6846, 6819, 6533, 6804, 6856, 6794, 6902, 6802, 6833, 6817, 6894, 6787, 6756, 6856, 6868, 6844, 6894, 6770, 6859, 6628, 6858, 6873, 6788, 6785, 6774, 6926, 6580, 6848, 6901, 6875, 6830, 6893, 6711, 6800, 6855, 6780, 6894, 6870, 6836, 6641, 6883, 6861, 6880, 6896, 6909, 6801, 6912, 6803, 6868, 6919, 6864, 6837, 6879, 6883, 6828, 6787, 6780, 6809, 6891, 6888, 6860, 6838, 6831, 6895, 6876, 6928, 6901, 6783, 6832, 6839, 6753, 6901, 6888, 6856, 6887, 6549, 6614, 6792, 6847, 6894, 6837, 6875, 6820, 6816, 6780, 6857, 6885, 6863, 6912, 6915, 6848, 6811, 6907, 6894, 6888, 6706, 6903, 6869, 6823, 6879, 6487, 6893, 6742, 6835, 6691, 6898, 6669, 6892, 6765, 6753, 6955, 6840, 6853, 6817, 6865, 6781, 6878, 6846, 6908, 6856, 6824, 6912, 6782, 6800, 6832, 6847, 6904, 6680, 6892, 6912, 6801, 6798, 6863, 6829, 6842, 6880, 6783, 6778, 6899, 6876, 6831, 6820, 6896, 6906, 6916, 6871, 6885, 6827, 6850, 6925, 6879, 6840, 6867, 6887, 6890, 6837, 6869, 6849, 6913, 6882, 6871, 6798, 6874, 6886, 6888, 6933, 6882, 6879, 6887, 6885, 6877, 6919, 6802, 6874, 6818, 6787, 6761, 6819, 6848, 6885, 6896, 6904, 6854, 6888, 6902, 6794, 6860, 6824, 6774, 6703, 6875, 6900, 6810, 6870, 6818, 6845, 6804, 6794, 6888, 6898, 6904, 6814, 6830, 6745, 6922, 6885, 6806, 6917, 6879, 6793, 6852, 6875, 6819, 6871, 6868, 6914, 6797, 6858, 6922, 6661, 6739, 6780, 6880, 6739, 6837, 6866, 6844, 6901, 6890, 6885, 6853, 6890, 6746, 6825, 6823, 6876, 6772, 6833, 6843, 6721])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6981, 6967, 6983, 6983, 6987, 6972, 6985, 6969, 6984, 6982, 6965, 6990, 6984, 6972, 6977, 6989, 6981, 6978, 6976, 6963, 6981, 6978, 6978, 6987, 6973, 6967, 6984, 6982, 6972, 6966, 6986, 6985, 6983, 6985, 6984, 6979, 6981, 6978, 6983, 6981, 6989, 6985, 6971, 6983, 6971, 6982, 6975, 6970, 6974, 6973, 6982, 6977, 6976, 6974, 6982, 6973, 6989, 6987, 6978, 6979, 6973, 6984, 6980, 6975, 6978, 6979, 6979, 6973, 6984, 6980, 6982, 6983, 6982, 6982, 6986, 6978, 6967, 6981, 6983, 6983, 6987, 6971, 6992, 6969, 6984, 6981, 6985, 6983, 6979, 6989, 6972, 6981, 6974, 6976, 6977, 6978, 6981, 6977, 6981, 6992, 6977, 6981, 6976, 6977, 6974, 6978, 6985, 6984, 6983, 6979, 6989, 6978, 6983, 6985, 6973, 6975, 6971, 6983, 6969, 6981, 6979, 6982, 6987, 6978, 6973, 6982, 6987, 6968, 6977, 6987, 6987, 6972, 6980, 6972, 6982, 6979, 6975, 6968, 6984, 6971, 6978, 6971, 6985, 6981, 6980, 6978, 6978, 6985, 6984, 6978, 6975, 6981, 6976, 6980, 6969, 6987, 6981, 6978, 6979, 6989, 6974, 6989, 6980, 6976, 6972, 6977, 6983, 6973, 6980, 6972, 6979, 6978, 6986, 6971, 6982, 6987, 6977, 6988, 6968, 6984, 6972, 6970, 6973, 6977, 6978, 6986, 6979, 6983, 6963, 6980, 6977, 6981, 6992, 6986, 6975, 6975, 6976, 6980, 6988, 6980, 6969, 6973, 6982, 6976, 6975, 6965, 6964, 6971, 6978, 6977, 6982, 6983, 6984, 6960, 6979, 6980, 6981, 6977, 6977, 6981, 6989, 6978, 6981, 6979, 6980, 6979, 6979, 6972, 6980, 6977, 6972, 6982, 6970, 6976, 6979, 6976, 6964, 6983, 6985, 6989, 6978, 6988, 6983, 6980, 6973, 6989, 6979, 6979, 6984, 6974, 6974, 6983, 6982, 6976, 6984, 6991])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6902, 6855, 6810, 6605, 6895, 6847, 6883, 6772, 6835, 6836, 6787, 6804, 6868, 6758, 6841, 6830, 6871, 6815, 6823, 6780, 6861, 6785, 6904, 6821, 6823, 6845, 6890, 6853, 6690, 6860, 6877, 6853, 6890, 6809, 6880, 6773, 6846, 6866, 6697, 6829, 6828, 6924, 6735, 6861, 6868, 6849, 6859, 6886, 6717, 6807, 6838, 6820, 6890, 6872, 6871, 6703, 6887, 6851, 6869, 6883, 6866, 6846, 6914, 6825, 6845, 6893, 6880, 6809, 6898, 6864, 6851, 6770, 6795, 6828, 6859, 6872, 6857, 6834, 6813, 6864, 6865, 6938, 6868, 6832, 6837, 6809, 6860, 6884, 6840, 6859, 6862, 6798, 6696, 6822, 6821, 6864, 6851, 6867, 6785, 6814, 6821, 6853, 6912, 6852, 6914, 6915, 6870, 6848, 6862, 6835, 6894, 6782, 6910, 6861, 6826, 6869, 6701, 6878, 6814, 6821, 6777, 6858, 6745, 6894, 6810, 6762, 6921, 6864, 6800, 6840, 6864, 6813, 6830, 6822, 6852, 6873, 6815, 6878, 6800, 6836, 6838, 6824, 6867, 6785, 6879, 6868, 6804, 6839, 6887, 6805, 6864, 6868, 6829, 6839, 6864, 6891, 6814, 6842, 6891, 6884, 6907, 6844, 6868, 6853, 6818, 6895, 6867, 6877, 6887, 6848, 6873, 6834, 6859, 6845, 6907, 6843, 6872, 6837, 6882, 6871, 6900, 6897, 6903, 6892, 6859, 6870, 6892, 6910, 6830, 6859, 6859, 6846, 6796, 6862, 6846, 6881, 6884, 6905, 6816, 6880, 6901, 6785, 6846, 6830, 6785, 6772, 6842, 6848, 6827, 6868, 6840, 6841, 6830, 6778, 6869, 6892, 6919, 6841, 6876, 6808, 6881, 6857, 6824, 6893, 6869, 6834, 6813, 6869, 6820, 6900, 6845, 6917, 6809, 6863, 6916, 6778, 6734, 6811, 6871, 6686, 6858, 6896, 6817, 6886, 6877, 6873, 6872, 6884, 6758, 6858, 6798, 6874, 6776, 6871, 6880, 6779])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6967, 6962, 6982, 6983, 6982, 6971, 6967, 6983, 6980, 6969, 6979, 6972, 6967, 6969, 6982, 6973, 6993, 6986, 6979, 6988, 6971, 6983, 6984, 6986, 6982, 6977, 6986, 6976, 6974, 6984, 6966, 6974, 6974, 6976, 6977, 6973, 6985, 6984, 6977, 6980, 6970, 6971, 6985, 6976, 6977, 6978, 6970, 6973, 6974, 6978, 6981, 6959, 6972, 6970, 6974, 6987, 6975, 6973, 6971, 6980, 6972, 6968, 6971, 6989, 6972, 6980, 6970, 6974, 6968, 6965, 6984, 6977, 6979, 6974, 6977, 6977, 6990, 6964, 6974, 6988, 6983, 6972, 6969, 6974, 6978, 6980, 6979, 6981, 6981, 6985, 6964, 6988, 6979, 6981, 6985, 6987, 6981, 6979, 6974, 6960, 6977, 6979, 6980, 6969, 6977, 6987, 6982, 6971, 6969, 6990, 6975, 6992, 6986, 6975, 6984, 6984, 6982, 6980, 6983, 6971, 6972, 6976, 6993, 6971, 6977, 6988, 6980, 6981, 6959, 6970, 6986, 6973, 6982, 6975, 6985, 6982, 6972, 6970, 6973, 6982, 6982, 6953, 6966, 6963, 6959, 6992, 6969, 6987, 6992, 6961, 6970, 6966, 6961, 6984, 6981, 6984, 6977, 6970, 6963, 6971, 6965, 6990, 6973, 6986, 6975, 6979, 6975, 6977, 6990, 6973, 6962, 6987, 6976, 6964, 6974, 6976, 6986, 6985, 6979, 6976, 6972, 6981, 6981, 6964, 6984, 6984, 6976, 6982, 6981, 6962, 6976, 6986, 6969, 6971, 6992, 6989, 6987, 6977, 6977, 6970, 6974, 6981, 6964, 6972, 6973, 6974, 6978, 6977, 6989, 6969, 6970, 6988, 6970, 6971, 6979, 6974, 6985, 6985, 6968, 6960, 6988, 6982, 6977, 6979, 6971, 6977, 6958, 6983, 6971, 6987, 6975, 6973, 6977, 6993, 6976, 6978, 6975, 6979, 6959, 6987, 6990, 6973, 6980, 6972, 6959, 6977, 6970, 6971, 6980, 6984, 6982, 6966, 6978, 6982, 6980, 6969])
Tensor(shape=[256], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [6917, 6903, 6827, 6715, 6896, 6824, 6881, 6781, 6889, 6876, 6825, 6855, 6899, 6844, 6859, 6862, 6881, 6838, 6852, 6847, 6863, 6807, 6892, 6878, 6846, 6845, 6905, 6883, 6799, 6883, 6859, 6837, 6866, 6828, 6897, 6840, 6851, 6879, 6790, 6893, 6859, 6872, 6807, 6891, 6880, 6852, 6879, 6874, 6777, 6866, 6833, 6873, 6877, 6891, 6881, 6811, 6887, 6864, 6882, 6868, 6907, 6898, 6908, 6837, 6885, 6858, 6877, 6846, 6900, 6842, 6873, 6823, 6849, 6850, 6868, 6879, 6865, 6867, 6830, 6895, 6845, 6910, 6903, 6821, 6846, 6855, 6892, 6891, 6855, 6891, 6867, 6792, 6807, 6858, 6830, 6887, 6892, 6874, 6878, 6815, 6842, 6871, 6894, 6867, 6906, 6907, 6890, 6849, 6874, 6846, 6893, 6792, 6938, 6883, 6807, 6854, 6733, 6928, 6864, 6791, 6772, 6872, 6859, 6879, 6838, 6748, 6890, 6834, 6806, 6838, 6905, 6839, 6825, 6851, 6833, 6854, 6832, 6886, 6796, 6842, 6830, 6837, 6877, 6857, 6864, 6878, 6803, 6860, 6867, 6822, 6880, 6863, 6826, 6872, 6877, 6874, 6848, 6834, 6871, 6887, 6905, 6876, 6876, 6865, 6840, 6896, 6887, 6850, 6848, 6846, 6898, 6860, 6870, 6848, 6891, 6842, 6872, 6882, 6866, 6862, 6889, 6873, 6916, 6858, 6858, 6843, 6899, 6918, 6848, 6867, 6893, 6922, 6830, 6884, 6886, 6851, 6870, 6888, 6841, 6873, 6884, 6853, 6862, 6831, 6847, 6762, 6850, 6859, 6827, 6871, 6871, 6837, 6878, 6813, 6892, 6888, 6869, 6863, 6842, 6765, 6874, 6879, 6866, 6861, 6860, 6797, 6843, 6872, 6876, 6877, 6875, 6905, 6846, 6840, 6907, 6775, 6733, 6864, 6866, 6872, 6879, 6884, 6867, 6877, 6897, 6877, 6856, 6876, 6777, 6835, 6860, 6887, 6847, 6894, 6896, 6693])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3493, 3497, 3494, 3496, 3495, 3498, 3496, 3495, 3495, 3494, 3488, 3491, 3496, 3496, 3491, 3494, 3498, 3495, 3497, 3494, 3491, 3492, 3487, 3495, 3494, 3495, 3495, 3494, 3490, 3493, 3498, 3495, 3495, 3494, 3494, 3497, 3494, 3490, 3488, 3497, 3493, 3498, 3492, 3496, 3492, 3489, 3494, 3493, 3492, 3492, 3491, 3493, 3497, 3493, 3497, 3491, 3495, 3494, 3491, 3495, 3497, 3492, 3491, 3495, 3493, 3495, 3490, 3496, 3493, 3495, 3497, 3494, 3498, 3496, 3494, 3492, 3495, 3496, 3491, 3497, 3494, 3495, 3492, 3497, 3497, 3489, 3493, 3492, 3499, 3490, 3491, 3494, 3495, 3497, 3498, 3494, 3495, 3493, 3495, 3496, 3491, 3493, 3496, 3494, 3495, 3490, 3493, 3492, 3495, 3495, 3489, 3492, 3494, 3492, 3491, 3490, 3491, 3491, 3492, 3486, 3496, 3496, 3493, 3493, 3495, 3496, 3495, 3493, 3491, 3498, 3496, 3491, 3490, 3497, 3494, 3496, 3499, 3492, 3492, 3495, 3491, 3497, 3492, 3493, 3490, 3493, 3493, 3491, 3492, 3496, 3493, 3493, 3494, 3494, 3492, 3495, 3490, 3492, 3496, 3494, 3496, 3496, 3498, 3494, 3496, 3487, 3492, 3495, 3493, 3489, 3494, 3494, 3495, 3492, 3487, 3494, 3497, 3493, 3492, 3498, 3493, 3495, 3498, 3498, 3495, 3496, 3496, 3492, 3494, 3490, 3495, 3493, 3492, 3497, 3490, 3490, 3495, 3494, 3494, 3499, 3488, 3495, 3490, 3498, 3497, 3492, 3492, 3498, 3494, 3497, 3494, 3491, 3494, 3497, 3496, 3498, 3491, 3494, 3489, 3495, 3496, 3493, 3487, 3491, 3491, 3497, 3493, 3493, 3491, 3493, 3495, 3490, 3494, 3492, 3489, 3495, 3493, 3496, 3496, 3496, 3497, 3487, 3493, 3497, 3493, 3494, 3495, 3488, 3496, 3492, 3491, 3495, 3495, 3493, 3493, 3498, 3495, 3498, 3497, 3499, 3495, 3496, 3492, 3493, 3496, 3495, 3490, 3496, 3493, 3498, 3496, 3495, 3494, 3497, 3491, 3495, 3493, 3499, 3494, 3487, 3497, 3498, 3496, 3493, 3494, 3496, 3496, 3494, 3491, 3496, 3494, 3495, 3497, 3496, 3493, 3494, 3493, 3497, 3491, 3491, 3495, 3494, 3500, 3496, 3490, 3490, 3492, 3495, 3497, 3496, 3491, 3493, 3493, 3496, 3494, 3492, 3492, 3492, 3495, 3493, 3495, 3490, 3490, 3497, 3493, 3497, 3494, 3493, 3492, 3492, 3493, 3495, 3496, 3492, 3489, 3494, 3495, 3493, 3495, 3494, 3494, 3492, 3492, 3493, 3497, 3490, 3492, 3492, 3494, 3493, 3491, 3494, 3494, 3493, 3493, 3494, 3495, 3493, 3495, 3493, 3493, 3494, 3496, 3493, 3488, 3492, 3497, 3493, 3495, 3490, 3491, 3493, 3494, 3492, 3494, 3493, 3496, 3495, 3495, 3497, 3492, 3496, 3497, 3498, 3496, 3493, 3494, 3497, 3493, 3497, 3494, 3497, 3493, 3495, 3498, 3495, 3497, 3494, 3494, 3497, 3494, 3492, 3492, 3492, 3492, 3499, 3492, 3483, 3492, 3498, 3495, 3493, 3498, 3492, 3493, 3495, 3495, 3493, 3489, 3493, 3495, 3492, 3494, 3493, 3492, 3494, 3495, 3498, 3495, 3492, 3496, 3494, 3496, 3494, 3496, 3493, 3489, 3493, 3495, 3494, 3488, 3491, 3490, 3493, 3491, 3491, 3496, 3491, 3495, 3496, 3494, 3495, 3495, 3491, 3494, 3494, 3497, 3492, 3495, 3493, 3494, 3497, 3492, 3493, 3494, 3496, 3491, 3496, 3497, 3497, 3496, 3493, 3496, 3497, 3492, 3492, 3494, 3493, 3494, 3494, 3494, 3494, 3492, 3495, 3491, 3497, 3496, 3497, 3492, 3494, 3496, 3493, 3496, 3495, 3497, 3497, 3492, 3495, 3494, 3497, 3496, 3495, 3495, 3493, 3496, 3491, 3494, 3495, 3496, 3492, 3494, 3495])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3465, 3469, 3462, 3470, 3462, 3471, 3468, 3466, 3467, 3466, 3463, 3468, 3464, 3464, 3463, 3467, 3468, 3471, 3471, 3463, 3464, 3455, 3472, 3465, 3460, 3480, 3462, 3470, 3475, 3472, 3468, 3453, 3466, 3463, 3462, 3463, 3469, 3453, 3463, 3453, 3472, 3456, 3469, 3467, 3478, 3465, 3471, 3475, 3463, 3460, 3471, 3472, 3475, 3465, 3471, 3475, 3466, 3463, 3468, 3471, 3459, 3467, 3459, 3468, 3470, 3487, 3461, 3460, 3469, 3468, 3470, 3467, 3459, 3473, 3468, 3454, 3465, 3459, 3475, 3464, 3470, 3473, 3467, 3463, 3457, 3466, 3470, 3455, 3463, 3477, 3467, 3465, 3454, 3457, 3471, 3479, 3466, 3457, 3467, 3464, 3469, 3462, 3473, 3473, 3470, 3473, 3461, 3462, 3457, 3463, 3461, 3465, 3459, 3468, 3478, 3470, 3474, 3472, 3457, 3458, 3467, 3466, 3470, 3465, 3467, 3467, 3466, 3459, 3461, 3470, 3460, 3456, 3464, 3468, 3454, 3474, 3468, 3464, 3476, 3475, 3447, 3462, 3464, 3451, 3466, 3468, 3459, 3461, 3450, 3464, 3465, 3470, 3468, 3467, 3462, 3454, 3476, 3456, 3455, 3460, 3466, 3456, 3462, 3464, 3473, 3463, 3455, 3471, 3467, 3469, 3466, 3468, 3461, 3465, 3467, 3467, 3464, 3464, 3465, 3472, 3471, 3470, 3461, 3470, 3472, 3466, 3473, 3466, 3466, 3463, 3450, 3473, 3466, 3470, 3487, 3478, 3466, 3463, 3483, 3459, 3469, 3468, 3470, 3461, 3459, 3460, 3462, 3460, 3465, 3458, 3469, 3468, 3474, 3456, 3466, 3470, 3464, 3455, 3465, 3463, 3458, 3458, 3458, 3468, 3465, 3472, 3463, 3462, 3461, 3479, 3469, 3455, 3456, 3471, 3466, 3463, 3465, 3479, 3454, 3467, 3469, 3455, 3467, 3469, 3466, 3465, 3459, 3468, 3463, 3464, 3468, 3468, 3465, 3466, 3456, 3465, 3467, 3468, 3474, 3472, 3476, 3470, 3463, 3465, 3469, 3486, 3471, 3463, 3462, 3466, 3470, 3475, 3471, 3469, 3462, 3471, 3474, 3459, 3467, 3470, 3461, 3476, 3462, 3465, 3467, 3474, 3476, 3471, 3458, 3469, 3461, 3456, 3462, 3461, 3463, 3473, 3463, 3464, 3491, 3462, 3472, 3464, 3462, 3457, 3467, 3466, 3473, 3467, 3473, 3475, 3467, 3460, 3471, 3478, 3463, 3467, 3476, 3470, 3456, 3465, 3453, 3477, 3452, 3480, 3474, 3457, 3444, 3469, 3460, 3456, 3462, 3471, 3473, 3472, 3472, 3457, 3472, 3467, 3469, 3457, 3473, 3464, 3464, 3455, 3474, 3452, 3474, 3473, 3468, 3459, 3452, 3466, 3458, 3467, 3467, 3466, 3462, 3474, 3464, 3475, 3467, 3466, 3461, 3470, 3461, 3465, 3465, 3468, 3463, 3473, 3474, 3451, 3462, 3461, 3466, 3468, 3475, 3461, 3469, 3465, 3471, 3455, 3471, 3474, 3470, 3454, 3454, 3459, 3468, 3471, 3462, 3474, 3462, 3469, 3471, 3473, 3469, 3464, 3464, 3475, 3466, 3465, 3476, 3475, 3461, 3464, 3464, 3466, 3471, 3473, 3471, 3475, 3471, 3462, 3471, 3465, 3467, 3470, 3479, 3462, 3468, 3464, 3461, 3476, 3462, 3463, 3465, 3461, 3460, 3463, 3471, 3484, 3467, 3465, 3463, 3469, 3464, 3464, 3468, 3466, 3464, 3473, 3464, 3474, 3467, 3455, 3459, 3461, 3465, 3467, 3467, 3460, 3459, 3457, 3462, 3461, 3471, 3463, 3477, 3466, 3466, 3466, 3468, 3469, 3471, 3456, 3469, 3475, 3471, 3468, 3471, 3477, 3476, 3457, 3456, 3467, 3462, 3476, 3468, 3465, 3462, 3463, 3458, 3463, 3473, 3462, 3467, 3474, 3469, 3457, 3457, 3465, 3458, 3467, 3470, 3471, 3456, 3463, 3452, 3466, 3470, 3459, 3468, 3460, 3469, 3472, 3466, 3471, 3463, 3469, 3466, 3451])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3476, 3481, 3477, 3483, 3481, 3487, 3486, 3483, 3484, 3484, 3492, 3480, 3490, 3489, 3488, 3483, 3479, 3481, 3475, 3487, 3484, 3482, 3485, 3488, 3475, 3482, 3483, 3478, 3480, 3487, 3475, 3488, 3479, 3484, 3477, 3482, 3477, 3484, 3484, 3485, 3474, 3477, 3478, 3476, 3476, 3481, 3485, 3489, 3483, 3487, 3484, 3491, 3479, 3482, 3479, 3485, 3482, 3488, 3483, 3482, 3481, 3488, 3477, 3484, 3479, 3479, 3486, 3485, 3484, 3478, 3484, 3478, 3485, 3480, 3487, 3485, 3488, 3478, 3488, 3471, 3487, 3478, 3479, 3483, 3484, 3486, 3485, 3488, 3486, 3482, 3488, 3487, 3480, 3484, 3485, 3479, 3479, 3485, 3480, 3476, 3485, 3485, 3480, 3478, 3481, 3485, 3476, 3478, 3486, 3475, 3480, 3482, 3479, 3475, 3483, 3484, 3473, 3476, 3473, 3480, 3482, 3485, 3478, 3483, 3490, 3479, 3473, 3480, 3491, 3487, 3490, 3475, 3473, 3481, 3484, 3480, 3481, 3482, 3482, 3479, 3475, 3479, 3488, 3479, 3487, 3484, 3480, 3472, 3482, 3478, 3487, 3483, 3476, 3485, 3487, 3487, 3480, 3482, 3487, 3483, 3489, 3487, 3483, 3487, 3482, 3480, 3475, 3484, 3478, 3478, 3477, 3473, 3469, 3485, 3477, 3481, 3473, 3488, 3486, 3482, 3475, 3479, 3485, 3482, 3485, 3483, 3475, 3480, 3488, 3483, 3492, 3486, 3481, 3482, 3487, 3490, 3483, 3485, 3485, 3481, 3481, 3475, 3481, 3489, 3485, 3474, 3482, 3475, 3479, 3483, 3485, 3483, 3484, 3480, 3486, 3481, 3472, 3474, 3481, 3487, 3479, 3485, 3485, 3484, 3491, 3484, 3487, 3484, 3467, 3483, 3488, 3485, 3473, 3481, 3486, 3483, 3482, 3490, 3481, 3488, 3482, 3487, 3483, 3486, 3485, 3483, 3473, 3481, 3480, 3485, 3485, 3482, 3484, 3486, 3482, 3483, 3478, 3483, 3478, 3481, 3476, 3481, 3485, 3481, 3477, 3487, 3480, 3482, 3478, 3486, 3478, 3486, 3482, 3481, 3476, 3486, 3472, 3483, 3485, 3489, 3486, 3486, 3485, 3483, 3482, 3485, 3479, 3490, 3478, 3489, 3492, 3477, 3477, 3477, 3485, 3475, 3482, 3481, 3480, 3482, 3487, 3485, 3484, 3486, 3475, 3477, 3479, 3484, 3486, 3480, 3489, 3481, 3486, 3480, 3478, 3482, 3488, 3487, 3487, 3485, 3479, 3484, 3474, 3483, 3477, 3483, 3479, 3476, 3484, 3484, 3481, 3485, 3476, 3479, 3485, 3484, 3485, 3486, 3472, 3482, 3481, 3486, 3481, 3480, 3481, 3477, 3483, 3481, 3487, 3480, 3481, 3473, 3486, 3488, 3480, 3492, 3480, 3478, 3483, 3486, 3482, 3480, 3487, 3473, 3487, 3482, 3488, 3486, 3482, 3480, 3482, 3482, 3480, 3483, 3486, 3480, 3480, 3476, 3475, 3480, 3479, 3481, 3484, 3480, 3484, 3478, 3487, 3481, 3480, 3487, 3486, 3483, 3485, 3487, 3475, 3487, 3479, 3485, 3483, 3483, 3481, 3490, 3481, 3486, 3480, 3485, 3480, 3482, 3478, 3482, 3484, 3478, 3487, 3476, 3487, 3480, 3484, 3481, 3482, 3486, 3489, 3486, 3476, 3485, 3486, 3486, 3474, 3481, 3476, 3483, 3476, 3480, 3484, 3480, 3483, 3480, 3483, 3479, 3485, 3479, 3488, 3480, 3480, 3484, 3476, 3482, 3489, 3486, 3482, 3481, 3484, 3488, 3479, 3482, 3479, 3484, 3491, 3479, 3485, 3484, 3486, 3472, 3486, 3477, 3482, 3481, 3481, 3484, 3484, 3480, 3481, 3479, 3478, 3486, 3478, 3483, 3476, 3481, 3480, 3487, 3479, 3482, 3486, 3491, 3482, 3485, 3471, 3482, 3485, 3488, 3482, 3478, 3478, 3481, 3487, 3484, 3489, 3470, 3489, 3478, 3476, 3482, 3477, 3482, 3480, 3478, 3483, 3471, 3484, 3483, 3478, 3483])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3495, 3494, 3494, 3495, 3495, 3490, 3498, 3496, 3482, 3491, 3495, 3491, 3492, 3490, 3490, 3494, 3492, 3496, 3492, 3492, 3491, 3494, 3492, 3484, 3495, 3489, 3491, 3494, 3491, 3487, 3487, 3486, 3490, 3491, 3489, 3488, 3491, 3493, 3491, 3496, 3494, 3492, 3487, 3493, 3495, 3491, 3497, 3493, 3489, 3495, 3487, 3492, 3491, 3493, 3491, 3496, 3491, 3495, 3495, 3491, 3491, 3494, 3491, 3489, 3491, 3493, 3493, 3494, 3489, 3496, 3496, 3489, 3493, 3487, 3494, 3494, 3493, 3493, 3491, 3494, 3495, 3492, 3491, 3493, 3492, 3491, 3496, 3491, 3494, 3492, 3496, 3492, 3487, 3496, 3495, 3480, 3487, 3489, 3493, 3491, 3493, 3493, 3496, 3492, 3490, 3490, 3495, 3493, 3489, 3490, 3493, 3492, 3495, 3490, 3492, 3494, 3487, 3494, 3490, 3490, 3490, 3491, 3490, 3488, 3488, 3495, 3490, 3494, 3496, 3497, 3488, 3490, 3497, 3491, 3492, 3490, 3490, 3486, 3489, 3494, 3488, 3489, 3488, 3491, 3484, 3491, 3492, 3489, 3488, 3492, 3496, 3489, 3491, 3486, 3493, 3487, 3492, 3497, 3496, 3489, 3494, 3491, 3492, 3493, 3491, 3491, 3494, 3491, 3494, 3487, 3495, 3491, 3494, 3495, 3493, 3488, 3497, 3492, 3493, 3492, 3491, 3490, 3494, 3491, 3495, 3495, 3490, 3493, 3490, 3495, 3490, 3492, 3495, 3487, 3494, 3492, 3492, 3493, 3488, 3489, 3496, 3494, 3490, 3489, 3493, 3493, 3493, 3495, 3492, 3490, 3491, 3491, 3487, 3495, 3493, 3493, 3495, 3494, 3493, 3493, 3489, 3493, 3497, 3495, 3494, 3489, 3491, 3493, 3491, 3489, 3491, 3494, 3494, 3486, 3493, 3492, 3494, 3495, 3495, 3493, 3492, 3493, 3493, 3495, 3493, 3491, 3492, 3496, 3489, 3491, 3488, 3495, 3492, 3497, 3496, 3490, 3487, 3492, 3496, 3494, 3492, 3491, 3495, 3495, 3497, 3495, 3489, 3491, 3497, 3494, 3495, 3489, 3494, 3492, 3490, 3492, 3493, 3493, 3494, 3493, 3485, 3489, 3493, 3492, 3489, 3489, 3489, 3487, 3486, 3491, 3490, 3498, 3487, 3497, 3494, 3495, 3491, 3495, 3495, 3494, 3489, 3494, 3489, 3494, 3494, 3488, 3490, 3493, 3495, 3491, 3492, 3482, 3492, 3497, 3492, 3497, 3493, 3491, 3490, 3493, 3488, 3492, 3498, 3489, 3495, 3491, 3494, 3492, 3494, 3494, 3496, 3490, 3488, 3495, 3488, 3494, 3484, 3492, 3493, 3493, 3495, 3493, 3496, 3490, 3494, 3492, 3488, 3494, 3492, 3492, 3492, 3493, 3488, 3496, 3495, 3490, 3494, 3494, 3495, 3494, 3493, 3491, 3493, 3494, 3494, 3493, 3495, 3494, 3493, 3494, 3493, 3496, 3493, 3488, 3491, 3498, 3487, 3491, 3498, 3495, 3492, 3492, 3489, 3489, 3489, 3493, 3487, 3487, 3487, 3492, 3492, 3493, 3495, 3491, 3494, 3489, 3490, 3491, 3494, 3490, 3491, 3494, 3496, 3491, 3495, 3491, 3496, 3488, 3491, 3496, 3492, 3493, 3490, 3493, 3490, 3491, 3498, 3490, 3492, 3495, 3491, 3490, 3492, 3494, 3491, 3487, 3495, 3493, 3495, 3495, 3494, 3493, 3496, 3491, 3492, 3493, 3485, 3489, 3493, 3493, 3493, 3496, 3490, 3494, 3495, 3493, 3489, 3494, 3498, 3494, 3494, 3496, 3493, 3493, 3493, 3496, 3489, 3491, 3489, 3495, 3486, 3497, 3494, 3495, 3489, 3498, 3494, 3489, 3491, 3491, 3494, 3491, 3489, 3495, 3493, 3492, 3489, 3490, 3493, 3491, 3496, 3490, 3491, 3493, 3497, 3496, 3491, 3494, 3493, 3493, 3490, 3488, 3496, 3489, 3495, 3493, 3494, 3493, 3493, 3495, 3496, 3494, 3493, 3494, 3494, 3488, 3488, 3495, 3492, 3489, 3495, 3486])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3366, 3357, 3380, 3368, 3342, 3363, 3340, 3352, 3344, 3367, 3351, 3352, 3369, 3351, 3354, 3369, 3310, 3374, 3346, 3347, 3454, 3352, 3338, 3342, 3364, 3373, 3368, 3361, 3384, 3380, 3419, 3354, 3360, 3339, 3361, 3387, 3343, 3319, 3349, 3352, 3346, 3352, 3370, 3368, 3341, 3398, 3354, 3373, 3348, 3359, 3341, 3401, 3377, 3354, 3356, 3368, 3346, 3334, 3384, 3359, 3395, 3337, 3353, 3380, 3384, 3377, 3352, 3361, 3350, 3366, 3375, 3323, 3359, 3403, 3396, 3341, 3356, 3360, 3379, 3361, 3357, 3392, 3354, 3360, 3356, 3387, 3354, 3379, 3358, 3389, 3358, 3356, 3373, 3323, 3327, 3349, 3356, 3362, 3351, 3369, 3364, 3381, 3356, 3371, 3345, 3387, 3363, 3360, 3389, 3332, 3324, 3370, 3366, 3387, 3384, 3359, 3358, 3390, 3394, 3361, 3372, 3375, 3326, 3351, 3366, 3358, 3359, 3340, 3360, 3390, 3343, 3317, 3341, 3351, 3361, 3349, 3339, 3335, 3351, 3382, 3350, 3339, 3342, 3347, 3375, 3381, 3363, 3366, 3349, 3367, 3342, 3362, 3343, 3357, 3364, 3346, 3359, 3339, 3317, 3347, 3346, 3361, 3356, 3350, 3364, 3362, 3364, 3364, 3344, 3354, 3370, 3370, 3358, 3341, 3330, 3372, 3387, 3358, 3384, 3369, 3357, 3377, 3370, 3344, 3367, 3359, 3341, 3328, 3370, 3362, 3361, 3354, 3335, 3387, 3376, 3381, 3354, 3345, 3376, 3357, 3348, 3361, 3369, 3337, 3327, 3367, 3370, 3380, 3393, 3364, 3388, 3347, 3372, 3375, 3348, 3349, 3389, 3366, 3373, 3354, 3361, 3450, 3358, 3331, 3369, 3337, 3357, 3370, 3364, 3349, 3332, 3358, 3348, 3394, 3339, 3361, 3349, 3381, 3366, 3356, 3311, 3356, 3356, 3322, 3368, 3354, 3377, 3327, 3350, 3363, 3355, 3394, 3361, 3352, 3378, 3351, 3374, 3368, 3354, 3348, 3346, 3383, 3381, 3369, 3336, 3476, 3345, 3385, 3339, 3373, 3341, 3359, 3367, 3418, 3379, 3371, 3329, 3386, 3365, 3363, 3363, 3399, 3348, 3383, 3441, 3375, 3451, 3332, 3340, 3343, 3378, 3346, 3342, 3364, 3379, 3373, 3363, 3355, 3403, 3352, 3360, 3358, 3342, 3353, 3342, 3362, 3376, 3343, 3344, 3357, 3355, 3355, 3389, 3333, 3372, 3380, 3367, 3365, 3342, 3347, 3365, 3365, 3349, 3397, 3344, 3377, 3340, 3364, 3347, 3356, 3352, 3356, 3399, 3350, 3374, 3341, 3366, 3356, 3361, 3323, 3368, 3333, 3337, 3353, 3369, 3345, 3377, 3345, 3353, 3352, 3340, 3382, 3358, 3362, 3361, 3381, 3374, 3336, 3357, 3365, 3372, 3390, 3339, 3343, 3361, 3380, 3321, 3344, 3371, 3391, 3371, 3357, 3331, 3371, 3369, 3361, 3352, 3352, 3365, 3389, 3355, 3329, 3363, 3376, 3337, 3346, 3345, 3354, 3392, 3359, 3340, 3380, 3344, 3361, 3357, 3344, 3371, 3381, 3410, 3362, 3342, 3342, 3357, 3347, 3349, 3371, 3337, 3346, 3354, 3363, 3359, 3382, 3347, 3340, 3353, 3350, 3384, 3352, 3395, 3351, 3356, 3356, 3355, 3378, 3352, 3402, 3347, 3356, 3382, 3362, 3349, 3366, 3321, 3380, 3380, 3341, 3379, 3351, 3352, 3447, 3348, 3363, 3329, 3371, 3376, 3360, 3379, 3350, 3351, 3345, 3370, 3358, 3366, 3341, 3385, 3373, 3327, 3366, 3373, 3392, 3353, 3356, 3378, 3371, 3377, 3356, 3392, 3382, 3387, 3365, 3362, 3358, 3357, 3369, 3360, 3366, 3379, 3341, 3367, 3390, 3362, 3339, 3366, 3385, 3376, 3381, 3349, 3370, 3337, 3339, 3361, 3363, 3340, 3368, 3346, 3367, 3342, 3384, 3321, 3365, 3326, 3352, 3355, 3350, 3355, 3342, 3400, 3357, 3341, 3377, 3361, 3313])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3484, 3492, 3493, 3489, 3488, 3487, 3485, 3488, 3490, 3492, 3490, 3491, 3493, 3493, 3489, 3487, 3488, 3485, 3486, 3494, 3489, 3490, 3494, 3494, 3490, 3487, 3490, 3490, 3494, 3486, 3490, 3492, 3489, 3487, 3490, 3486, 3495, 3487, 3485, 3485, 3486, 3486, 3494, 3492, 3489, 3486, 3492, 3491, 3490, 3492, 3488, 3496, 3491, 3489, 3490, 3481, 3493, 3482, 3493, 3492, 3487, 3489, 3489, 3494, 3487, 3491, 3490, 3488, 3488, 3495, 3490, 3488, 3491, 3482, 3490, 3493, 3489, 3486, 3482, 3491, 3484, 3488, 3493, 3486, 3493, 3491, 3485, 3485, 3488, 3489, 3495, 3500, 3492, 3493, 3495, 3487, 3492, 3486, 3492, 3491, 3487, 3491, 3490, 3496, 3493, 3489, 3496, 3491, 3488, 3494, 3493, 3491, 3491, 3494, 3489, 3488, 3491, 3485, 3483, 3492, 3487, 3490, 3490, 3487, 3491, 3489, 3490, 3491, 3483, 3488, 3493, 3486, 3489, 3492, 3492, 3489, 3489, 3489, 3487, 3489, 3487, 3488, 3492, 3488, 3489, 3493, 3486, 3488, 3486, 3494, 3493, 3490, 3489, 3489, 3485, 3487, 3489, 3487, 3493, 3489, 3487, 3489, 3492, 3490, 3493, 3492, 3489, 3495, 3491, 3490, 3492, 3486, 3485, 3491, 3485, 3492, 3490, 3484, 3490, 3485, 3490, 3489, 3484, 3486, 3488, 3483, 3487, 3492, 3492, 3489, 3487, 3483, 3491, 3487, 3491, 3493, 3492, 3489, 3487, 3491, 3481, 3491, 3485, 3492, 3493, 3490, 3494, 3488, 3484, 3487, 3486, 3494, 3494, 3486, 3488, 3485, 3488, 3491, 3487, 3485, 3492, 3489, 3487, 3491, 3491, 3487, 3495, 3490, 3489, 3490, 3493, 3486, 3493, 3492, 3491, 3481, 3489, 3489, 3492, 3486, 3490, 3489, 3487, 3488, 3488, 3484, 3486, 3491, 3487, 3492, 3494, 3493, 3485, 3492, 3495, 3493, 3490, 3490, 3490, 3493, 3487, 3492, 3490, 3487, 3487, 3484, 3496, 3495, 3485, 3488, 3489, 3492, 3488, 3491, 3490, 3493, 3487, 3486, 3489, 3490, 3491, 3488, 3489, 3488, 3488, 3495, 3493, 3495, 3483, 3484, 3489, 3488, 3487, 3485, 3490, 3487, 3494, 3492, 3486, 3492, 3484, 3487, 3493, 3484, 3485, 3484, 3488, 3489, 3493, 3488, 3483, 3491, 3493, 3486, 3487, 3491, 3490, 3493, 3490, 3496, 3490, 3494, 3489, 3483, 3486, 3494, 3490, 3487, 3491, 3493, 3497, 3492, 3487, 3493, 3487, 3487, 3489, 3491, 3489, 3488, 3491, 3496, 3487, 3491, 3491, 3488, 3486, 3493, 3489, 3489, 3490, 3495, 3491, 3495, 3489, 3492, 3487, 3491, 3489, 3491, 3487, 3490, 3488, 3489, 3490, 3485, 3485, 3492, 3490, 3489, 3492, 3485, 3490, 3495, 3492, 3492, 3494, 3487, 3493, 3492, 3489, 3492, 3484, 3490, 3488, 3491, 3491, 3490, 3493, 3487, 3492, 3486, 3493, 3491, 3489, 3486, 3487, 3486, 3494, 3486, 3490, 3492, 3481, 3493, 3492, 3487, 3493, 3486, 3489, 3491, 3492, 3487, 3493, 3488, 3491, 3490, 3489, 3487, 3488, 3489, 3491, 3488, 3488, 3489, 3492, 3490, 3492, 3490, 3488, 3488, 3490, 3492, 3485, 3486, 3494, 3490, 3490, 3496, 3492, 3491, 3489, 3491, 3489, 3490, 3491, 3492, 3490, 3491, 3489, 3489, 3487, 3492, 3490, 3480, 3496, 3489, 3492, 3491, 3488, 3488, 3496, 3484, 3489, 3493, 3487, 3493, 3487, 3493, 3486, 3486, 3489, 3490, 3489, 3486, 3488, 3492, 3492, 3491, 3494, 3494, 3493, 3491, 3486, 3489, 3488, 3488, 3486, 3486, 3481, 3492, 3489, 3490, 3494, 3492, 3486, 3490, 3494, 3489, 3492, 3490, 3490, 3493, 3490, 3493, 3486, 3493, 3492, 3484, 3486, 3488, 3488, 3493])
Tensor(shape=[512], dtype=int64, place=CUDAPlace(0), stop_gradient=True,
       [3249, 3270, 3261, 3226, 3208, 3263, 3238, 3206, 3225, 3282, 3197, 3229, 3266, 3227, 3241, 3212, 3181, 3229, 3251, 3255, 3201, 3247, 3241, 3215, 3256, 3273, 3236, 3266, 3246, 3222, 3248, 3261, 3248, 3232, 3256, 3230, 3220, 3222, 3257, 3228, 3260, 3217, 3251, 3237, 3237, 3259, 3279, 3206, 3226, 3244, 3241, 3243, 3246, 3217, 3240, 3270, 3221, 3236, 3278, 3248, 3236, 3247, 3235, 3241, 3216, 3260, 3244, 3227, 3241, 3246, 3275, 3246, 3244, 3246, 3244, 3244, 3240, 3213, 3345, 3246, 3240, 3235, 3209, 3229, 3228, 3264, 3191, 3242, 3210, 3265, 3239, 3212, 3143, 3230, 3208, 3255, 3250, 3225, 3216, 3251, 3211, 3258, 3270, 3250, 3221, 3248, 3238, 3230, 3244, 3236, 3233, 3237, 3242, 3231, 3234, 3254, 3259, 3237, 3214, 3188, 3248, 3212, 3215, 3256, 3267, 3259, 3241, 3205, 3291, 3261, 3226, 3225, 3232, 3227, 3207, 3283, 3207, 3238, 3243, 3264, 3245, 3211, 3258, 3223, 3226, 3235, 3224, 3255, 3196, 3249, 3224, 3217, 3223, 3187, 3253, 3249, 3204, 3246, 3222, 3180, 3207, 3233, 3252, 3222, 3256, 3253, 3244, 3234, 3199, 3239, 3254, 3245, 3242, 3234, 3245, 3244, 3239, 3226, 3235, 3240, 3217, 3251, 3268, 3214, 3267, 3233, 3233, 3220, 3234, 3216, 3222, 3224, 3238, 3248, 3259, 3214, 3220, 3242, 3243, 3225, 3238, 3247, 3261, 3195, 3228, 3227, 3248, 3220, 3281, 3236, 3259, 3257, 3234, 3240, 3220, 3246, 3256, 3244, 3241, 3260, 3248, 3247, 3231, 3214, 3274, 3245, 3268, 3238, 3224, 3242, 3234, 3244, 3215, 3227, 3224, 3234, 3266, 3274, 3214, 3244, 3191, 3248, 3223, 3218, 3227, 3226, 3248, 3245, 3228, 3195, 3215, 3264, 3243, 3241, 3274, 3207, 3267, 3271, 3247, 3227, 3239, 3247, 3247, 3272, 3228, 3232, 3242, 3202, 3226, 3242, 3237, 3250, 3271, 3193, 3273, 3231, 3260, 3214, 3246, 3251, 3225, 3252, 3269, 3248, 3250, 3301, 3268, 3208, 3233, 3239, 3224, 3206, 3208, 3235, 3252, 3234, 3271, 3252, 3253, 3255, 3253, 3196, 3225, 3255, 3233, 3233, 3250, 3252, 3234, 3229, 3254, 3249, 3264, 3229, 3246, 3267, 3301, 3241, 3225, 3228, 3242, 3280, 3243, 3239, 3231, 3244, 3198, 3220, 3251, 3208, 3218, 3243, 3235, 3246, 3250, 3241, 3221, 3238, 3275, 3227, 3227, 3235, 3232, 3233, 3202, 3245, 3240, 3209, 3233, 3237, 3227, 3263, 3219, 3197, 3222, 3248, 3239, 3251, 3230, 3219, 3287, 3212, 3247, 3241, 3228, 3228, 3218, 3248, 3235, 3245, 3261, 3207, 3235, 3231, 3249, 3253, 3242, 3247, 3239, 3244, 3247, 3204, 3235, 3247, 3244, 3248, 3220, 3205, 3243, 3285, 3242, 3270, 3221, 3244, 3211, 3274, 3268, 3253, 3248, 3227, 3238, 3215, 3253, 3229, 3207, 3201, 3258, 3217, 3210, 3231, 3232, 3238, 3222, 3237, 3215, 3250, 3254, 3224, 3285, 3211, 3236, 3251, 3245, 3249, 3244, 3281, 3230, 3224, 3218, 3243, 3216, 3208, 3224, 3236, 3256, 3246, 3259, 3262, 3236, 3259, 3239, 3225, 3243, 3240, 3240, 3331, 3215, 3233, 3230, 3206, 3264, 3229, 3257, 3208, 3203, 3253, 3219, 3225, 3254, 3252, 3248, 3240, 3254, 3245, 3239, 3238, 3166, 3269, 3255, 3198, 3240, 3257, 3219, 3226, 3240, 3254, 3260, 3233, 3275, 3234, 3228, 3238, 3228, 3241, 3256, 3234, 3215, 3251, 3226, 3222, 3218, 3218, 3253, 3242, 3218, 3223, 3251, 3220, 3213, 3228, 3235, 3249, 3251, 3228, 3213, 3183, 3220, 3230, 3234, 3272, 3240, 3243])
2021-02-03 03:16:11,901-INFO: FLOPs after pruning: 3621506.329GFLOPs; pruned ratio: None
W0203 03:16:11.911118   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 1 times with reason: Connection refused retry after 0.5 seconds
W0203 03:16:12.411458   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 2 times with reason: Connection refused retry after 1 seconds
W0203 03:16:13.411680   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 3 times with reason: Connection refused retry after 1.5 seconds
W0203 03:16:14.911978   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 4 times with reason: Connection refused retry after 2 seconds
W0203 03:16:16.912230   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 5 times with reason: Connection refused retry after 2.5 seconds
W0203 03:16:19.412470   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 6 times with reason: Connection refused retry after 3 seconds
W0203 03:16:22.412725   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 7 times with reason: Connection refused retry after 3 seconds
W0203 03:16:25.412976   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 8 times with reason: Connection refused retry after 3 seconds
W0203 03:16:28.413234   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 9 times with reason: Connection refused retry after 3 seconds
W0203 03:16:31.413513   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 10 times with reason: Connection refused retry after 3 seconds
W0203 03:16:34.413767   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 11 times with reason: Connection refused retry after 3 seconds
W0203 03:16:37.414044   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 12 times with reason: Connection refused retry after 3 seconds
W0203 03:16:40.414350   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 13 times with reason: Connection refused retry after 3 seconds
W0203 03:16:43.414625   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 14 times with reason: Connection refused retry after 3 seconds
W0203 03:16:46.414912   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 15 times with reason: Connection refused retry after 3 seconds
W0203 03:16:49.415191   728 gen_comm_id_helper.cc:116] connect addr=127.0.0.1:60434 failed 16 times with reason: Connection refused retry after 3 seconds
I0203 03:16:52.416055   728 nccl_context.cc:68] init nccl context nranks: 4 local rank: 0 gpu id: 0 ring id: 0
The loss value printed in the log is the current step, and the metric is the average value of previous step.
Epoch 1/120
/usr/local/lib/python3.7/site-packages/paddle/fluid/layers/utils.py:77: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working
  return (isinstance(seq, collections.Sequence) and

step   10/5005 [..............................] - loss: 3.2875 - acc_top1: 0.4922 - acc_top5: 0.7266 - ETA: 2:25:30 - 2s/step
step   20/5005 [..............................] - loss: 4.9498 - acc_top1: 0.3305 - acc_top5: 0.5656 - ETA: 1:18:31 - 945ms/step
step   30/5005 [..............................] - loss: 4.8842 - acc_top1: 0.2646 - acc_top5: 0.4724 - ETA: 55:55 - 674ms/step  
step   40/5005 [..............................] - loss: 5.0802 - acc_top1: 0.2293 - acc_top5: 0.4254 - ETA: 46:25 - 561ms/step
step   50/5005 [..............................] - loss: 3.9210 - acc_top1: 0.2112 - acc_top5: 0.4037 - ETA: 39:23 - 477ms/step
step   60/5005 [..............................] - loss: 4.1037 - acc_top1: 0.2021 - acc_top5: 0.3953 - ETA: 35:06 - 426ms/step
step   70/5005 [..............................] - loss: 4.1253 - acc_top1: 0.1996 - acc_top5: 0.3984 - ETA: 31:37 - 384ms/step
step   80/5005 [..............................] - loss: 3.9152 - acc_top1: 0.2004 - acc_top5: 0.4043 - ETA: 28:48 - 351ms/step
step   90/5005 [..............................] - loss: 4.1605 - acc_top1: 0.2035 - acc_top5: 0.4108 - ETA: 26:50 - 328ms/step
step  100/5005 [..............................] - loss: 3.7735 - acc_top1: 0.2044 - acc_top5: 0.4148 - ETA: 25:34 - 313ms/step
step  110/5005 [..............................] - loss: 3.8224 - acc_top1: 0.2080 - acc_top5: 0.4202 - ETA: 24:38 - 302ms/step
step  120/5005 [..............................] - loss: 4.1921 - acc_top1: 0.2116 - acc_top5: 0.4259 - ETA: 24:10 - 297ms/step
step  130/5005 [..............................] - loss: 3.9671 - acc_top1: 0.2149 - acc_top5: 0.4296 - ETA: 23:06 - 284ms/step
step  140/5005 [..............................] - loss: 3.5001 - acc_top1: 0.2180 - acc_top5: 0.4327 - ETA: 22:33 - 278ms/step
step  150/5005 [..............................] - loss: 4.2035 - acc_top1: 0.2208 - acc_top5: 0.4365 - ETA: 21:46 - 269ms/step
step  160/5005 [..............................] - loss: 3.7466 - acc_top1: 0.2228 - acc_top5: 0.4391 - ETA: 21:05 - 261ms/step
step  170/5005 [>.............................] - loss: 3.6054 - acc_top1: 0.2255 - acc_top5: 0.4426 - ETA: 20:56 - 260ms/step
step  180/5005 [>.............................] - loss: 3.7295 - acc_top1: 0.2288 - acc_top5: 0.4484 - ETA: 20:37 - 256ms/step
step  190/5005 [>.............................] - loss: 4.1828 - acc_top1: 0.2312 - acc_top5: 0.4512 - ETA: 20:18 - 253ms/step
step  200/5005 [>.............................] - loss: 4.1148 - acc_top1: 0.2331 - acc_top5: 0.4548 - ETA: 19:52 - 248ms/step
step  210/5005 [>.............................] - loss: 3.4671 - acc_top1: 0.2354 - acc_top5: 0.4570 - ETA: 19:23 - 243ms/step
step  220/5005 [>.............................] - loss: 3.4510 - acc_top1: 0.2380 - acc_top5: 0.4604 - ETA: 19:22 - 243ms/step
step  230/5005 [>.............................] - loss: 3.6060 - acc_top1: 0.2397 - acc_top5: 0.4623 - ETA: 19:10 - 241ms/step
step  240/5005 [>.............................] - loss: 3.2706 - acc_top1: 0.2404 - acc_top5: 0.4637 - ETA: 19:11 - 242ms/step
step  250/5005 [>.............................] - loss: 3.1823 - acc_top1: 0.2426 - acc_top5: 0.4666 - ETA: 19:04 - 241ms/step
step  260/5005 [>.............................] - loss: 3.7226 - acc_top1: 0.2430 - acc_top5: 0.4674 - ETA: 18:56 - 239ms/step
step  270/5005 [>.............................] - loss: 3.4335 - acc_top1: 0.2448 - acc_top5: 0.4702 - ETA: 18:59 - 241ms/step
step  280/5005 [>.............................] - loss: 3.0659 - acc_top1: 0.2467 - acc_top5: 0.4742 - ETA: 18:50 - 239ms/step
step  290/5005 [>.............................] - loss: 3.5183 - acc_top1: 0.2493 - acc_top5: 0.4768 - ETA: 18:40 - 238ms/step
step  300/5005 [>.............................] - loss: 3.5488 - acc_top1: 0.2519 - acc_top5: 0.4802 - ETA: 18:21 - 234ms/step
step  310/5005 [>.............................] - loss: 2.9118 - acc_top1: 0.2545 - acc_top5: 0.4834 - ETA: 18:11 - 233ms/step
step  320/5005 [>.............................] - loss: 3.5237 - acc_top1: 0.2560 - acc_top5: 0.4866 - ETA: 18:00 - 231ms/step
step  330/5005 [>.............................] - loss: 3.0181 - acc_top1: 0.2583 - acc_top5: 0.4898 - ETA: 17:51 - 229ms/step
step  340/5005 [=>............................] - loss: 2.6832 - acc_top1: 0.2614 - acc_top5: 0.4928 - ETA: 17:47 - 229ms/step
step  350/5005 [=>............................] - loss: 3.2677 - acc_top1: 0.2630 - acc_top5: 0.4945 - ETA: 17:36 - 227ms/step
step  360/5005 [=>............................] - loss: 3.4723 - acc_top1: 0.2644 - acc_top5: 0.4965 - ETA: 17:26 - 225ms/step
step  370/5005 [=>............................] - loss: 2.9102 - acc_top1: 0.2658 - acc_top5: 0.4988 - ETA: 17:14 - 223ms/step
step  380/5005 [=>............................] - loss: 3.3826 - acc_top1: 0.2678 - acc_top5: 0.5009 - ETA: 17:02 - 221ms/step
step  390/5005 [=>............................] - loss: 2.9465 - acc_top1: 0.2697 - acc_top5: 0.5026 - ETA: 17:02 - 222ms/step
step  400/5005 [=>............................] - loss: 3.0395 - acc_top1: 0.2716 - acc_top5: 0.5046 - ETA: 17:01 - 222ms/step
step  410/5005 [=>............................] - loss: 3.1676 - acc_top1: 0.2729 - acc_top5: 0.5066 - ETA: 16:49 - 220ms/step
step  420/5005 [=>............................] - loss: 2.9352 - acc_top1: 0.2744 - acc_top5: 0.5083 - ETA: 16:39 - 218ms/step
step  430/5005 [=>............................] - loss: 3.4949 - acc_top1: 0.2753 - acc_top5: 0.5097 - ETA: 16:32 - 217ms/step
step  440/5005 [=>............................] - loss: 3.8620 - acc_top1: 0.2762 - acc_top5: 0.5108 - ETA: 16:31 - 217ms/step
step  450/5005 [=>............................] - loss: 3.4525 - acc_top1: 0.2777 - acc_top5: 0.5130 - ETA: 16:23 - 216ms/step
step  460/5005 [=>............................] - loss: 2.6233 - acc_top1: 0.2785 - acc_top5: 0.5142 - ETA: 16:21 - 216ms/step
step  470/5005 [=>............................] - loss: 3.0014 - acc_top1: 0.2797 - acc_top5: 0.5156 - ETA: 16:15 - 215ms/step
step  480/5005 [=>............................] - loss: 3.4537 - acc_top1: 0.2810 - acc_top5: 0.5178 - ETA: 16:11 - 215ms/step
step  490/5005 [=>............................] - loss: 3.0624 - acc_top1: 0.2825 - acc_top5: 0.5193 - ETA: 16:01 - 213ms/step
step  500/5005 [=>............................] - loss: 2.7063 - acc_top1: 0.2834 - acc_top5: 0.5208 - ETA: 15:56 - 212ms/step
step  510/5005 [==>...........................] - loss: 2.8965 - acc_top1: 0.2848 - acc_top5: 0.5231 - ETA: 15:56 - 213ms/step
step  520/5005 [==>...........................] - loss: 2.8797 - acc_top1: 0.2862 - acc_top5: 0.5252 - ETA: 15:49 - 212ms/step
step  530/5005 [==>...........................] - loss: 3.0479 - acc_top1: 0.2869 - acc_top5: 0.5264 - ETA: 15:41 - 210ms/step
step  540/5005 [==>...........................] - loss: 2.5867 - acc_top1: 0.2882 - acc_top5: 0.5275 - ETA: 15:43 - 211ms/step
step  550/5005 [==>...........................] - loss: 2.6292 - acc_top1: 0.2894 - acc_top5: 0.5291 - ETA: 15:35 - 210ms/step
step  560/5005 [==>...........................] - loss: 3.3008 - acc_top1: 0.2898 - acc_top5: 0.5295 - ETA: 15:31 - 210ms/step
step  570/5005 [==>...........................] - loss: 3.2591 - acc_top1: 0.2919 - acc_top5: 0.5312 - ETA: 15:30 - 210ms/step
step  580/5005 [==>...........................] - loss: 2.9138 - acc_top1: 0.2935 - acc_top5: 0.5331 - ETA: 15:24 - 209ms/step
step  590/5005 [==>...........................] - loss: 3.5411 - acc_top1: 0.2949 - acc_top5: 0.5350 - ETA: 15:16 - 208ms/step
step  600/5005 [==>...........................] - loss: 2.9440 - acc_top1: 0.2957 - acc_top5: 0.5362 - ETA: 15:19 - 209ms/step
step  610/5005 [==>...........................] - loss: 2.9809 - acc_top1: 0.2975 - acc_top5: 0.5381 - ETA: 15:12 - 208ms/step
step  620/5005 [==>...........................] - loss: 2.7813 - acc_top1: 0.2985 - acc_top5: 0.5394 - ETA: 15:09 - 207ms/step
step  630/5005 [==>...........................] - loss: 3.2645 - acc_top1: 0.2997 - acc_top5: 0.5411 - ETA: 15:04 - 207ms/step
step  640/5005 [==>...........................] - loss: 2.9239 - acc_top1: 0.3009 - acc_top5: 0.5426 - ETA: 15:02 - 207ms/step
step  650/5005 [==>...........................] - loss: 2.5766 - acc_top1: 0.3018 - acc_top5: 0.5438 - ETA: 14:55 - 206ms/step
step  660/5005 [==>...........................] - loss: 2.9415 - acc_top1: 0.3025 - acc_top5: 0.5448 - ETA: 14:53 - 206ms/step
step  670/5005 [===>..........................] - loss: 3.2838 - acc_top1: 0.3032 - acc_top5: 0.5463 - ETA: 14:50 - 206ms/step
step  680/5005 [===>..........................] - loss: 3.1459 - acc_top1: 0.3044 - acc_top5: 0.5474 - ETA: 14:45 - 205ms/step
step  690/5005 [===>..........................] - loss: 2.8720 - acc_top1: 0.3059 - acc_top5: 0.5490 - ETA: 14:40 - 204ms/step
step  700/5005 [===>..........................] - loss: 3.2174 - acc_top1: 0.3069 - acc_top5: 0.5503 - ETA: 14:32 - 203ms/step
step  710/5005 [===>..........................] - loss: 2.8091 - acc_top1: 0.3083 - acc_top5: 0.5514 - ETA: 14:27 - 202ms/step
step  720/5005 [===>..........................] - loss: 2.8462 - acc_top1: 0.3091 - acc_top5: 0.5528 - ETA: 14:25 - 202ms/step
step  730/5005 [===>..........................] - loss: 2.9211 - acc_top1: 0.3104 - acc_top5: 0.5539 - ETA: 14:25 - 202ms/step
step  740/5005 [===>..........................] - loss: 2.7260 - acc_top1: 0.3116 - acc_top5: 0.5556 - ETA: 14:20 - 202ms/step
step  750/5005 [===>..........................] - loss: 2.7520 - acc_top1: 0.3122 - acc_top5: 0.5562 - ETA: 14:15 - 201ms/step
step  760/5005 [===>..........................] - loss: 3.0724 - acc_top1: 0.3130 - acc_top5: 0.5575 - ETA: 14:11 - 201ms/step
step  770/5005 [===>..........................] - loss: 3.0303 - acc_top1: 0.3141 - acc_top5: 0.5588 - ETA: 14:10 - 201ms/step
step  780/5005 [===>..........................] - loss: 2.4171 - acc_top1: 0.3152 - acc_top5: 0.5602 - ETA: 14:08 - 201ms/step
step  790/5005 [===>..........................] - loss: 3.0643 - acc_top1: 0.3160 - acc_top5: 0.5612 - ETA: 14:06 - 201ms/step
step  800/5005 [===>..........................] - loss: 2.5381 - acc_top1: 0.3167 - acc_top5: 0.5624 - ETA: 14:01 - 200ms/step
step  810/5005 [===>..........................] - loss: 2.5095 - acc_top1: 0.3175 - acc_top5: 0.5634 - ETA: 14:01 - 201ms/step
step  820/5005 [===>..........................] - loss: 3.0449 - acc_top1: 0.3183 - acc_top5: 0.5643 - ETA: 13:59 - 200ms/step
step  830/5005 [===>..........................] - loss: 2.4846 - acc_top1: 0.3191 - acc_top5: 0.5655 - ETA: 13:57 - 201ms/step
step  840/5005 [====>.........................] - loss: 3.0206 - acc_top1: 0.3205 - acc_top5: 0.5672 - ETA: 13:55 - 201ms/step
step  850/5005 [====>.........................] - loss: 2.7797 - acc_top1: 0.3213 - acc_top5: 0.5677 - ETA: 13:51 - 200ms/step
step  860/5005 [====>.........................] - loss: 2.8351 - acc_top1: 0.3222 - acc_top5: 0.5685 - ETA: 13:47 - 200ms/step
step  870/5005 [====>.........................] - loss: 2.6956 - acc_top1: 0.3229 - acc_top5: 0.5693 - ETA: 13:46 - 200ms/step
step  880/5005 [====>.........................] - loss: 2.7715 - acc_top1: 0.3237 - acc_top5: 0.5703 - ETA: 13:44 - 200ms/step
step  890/5005 [====>.........................] - loss: 2.4770 - acc_top1: 0.3244 - acc_top5: 0.5715 - ETA: 13:38 - 199ms/step
step  900/5005 [====>.........................] - loss: 2.9134 - acc_top1: 0.3252 - acc_top5: 0.5723 - ETA: 13:35 - 199ms/step
step  910/5005 [====>.........................] - loss: 2.6691 - acc_top1: 0.3262 - acc_top5: 0.5730 - ETA: 13:33 - 199ms/step
step  920/5005 [====>.........................] - loss: 3.0962 - acc_top1: 0.3269 - acc_top5: 0.5737 - ETA: 13:29 - 198ms/step
step  930/5005 [====>.........................] - loss: 2.5405 - acc_top1: 0.3275 - acc_top5: 0.5747 - ETA: 13:24 - 197ms/step
step  940/5005 [====>.........................] - loss: 2.4354 - acc_top1: 0.3286 - acc_top5: 0.5757 - ETA: 13:22 - 197ms/step
step  950/5005 [====>.........................] - loss: 2.6629 - acc_top1: 0.3293 - acc_top5: 0.5764 - ETA: 13:19 - 197ms/step
step  960/5005 [====>.........................] - loss: 2.6240 - acc_top1: 0.3301 - acc_top5: 0.5771 - ETA: 13:16 - 197ms/step
step  970/5005 [====>.........................] - loss: 2.8653 - acc_top1: 0.3306 - acc_top5: 0.5781 - ETA: 13:14 - 197ms/step
step  980/5005 [====>.........................] - loss: 2.2788 - acc_top1: 0.3314 - acc_top5: 0.5790 - ETA: 13:09 - 196ms/step
step  990/5005 [====>.........................] - loss: 2.9061 - acc_top1: 0.3320 - acc_top5: 0.5797 - ETA: 13:07 - 196ms/step
step 1000/5005 [====>.........................] - loss: 2.5867 - acc_top1: 0.3328 - acc_top5: 0.5804 - ETA: 13:03 - 196ms/step
step 1010/5005 [=====>........................] - loss: 2.9666 - acc_top1: 0.3333 - acc_top5: 0.5815 - ETA: 13:02 - 196ms/step
step 1020/5005 [=====>........................] - loss: 2.9449 - acc_top1: 0.3343 - acc_top5: 0.5822 - ETA: 12:59 - 196ms/step
step 1030/5005 [=====>........................] - loss: 2.3180 - acc_top1: 0.3351 - acc_top5: 0.5830 - ETA: 12:58 - 196ms/step
step 1040/5005 [=====>........................] - loss: 2.6788 - acc_top1: 0.3360 - acc_top5: 0.5841 - ETA: 12:55 - 195ms/step
step 1050/5005 [=====>........................] - loss: 3.1801 - acc_top1: 0.3368 - acc_top5: 0.5850 - ETA: 12:54 - 196ms/step
step 1060/5005 [=====>........................] - loss: 3.2236 - acc_top1: 0.3374 - acc_top5: 0.5856 - ETA: 12:50 - 195ms/step
step 1070/5005 [=====>........................] - loss: 2.2973 - acc_top1: 0.3380 - acc_top5: 0.5863 - ETA: 12:47 - 195ms/step
step 1080/5005 [=====>........................] - loss: 2.4844 - acc_top1: 0.3389 - acc_top5: 0.5871 - ETA: 12:44 - 195ms/step
step 1090/5005 [=====>........................] - loss: 3.1766 - acc_top1: 0.3397 - acc_top5: 0.5879 - ETA: 12:43 - 195ms/step
step 1100/5005 [=====>........................] - loss: 3.0139 - acc_top1: 0.3405 - acc_top5: 0.5888 - ETA: 12:40 - 195ms/step
step 1110/5005 [=====>........................] - loss: 2.3394 - acc_top1: 0.3413 - acc_top5: 0.5895 - ETA: 12:39 - 195ms/step
step 1120/5005 [=====>........................] - loss: 3.0938 - acc_top1: 0.3415 - acc_top5: 0.5901 - ETA: 12:36 - 195ms/step
step 1130/5005 [=====>........................] - loss: 2.6495 - acc_top1: 0.3422 - acc_top5: 0.5909 - ETA: 12:34 - 195ms/step
step 1140/5005 [=====>........................] - loss: 3.0140 - acc_top1: 0.3426 - acc_top5: 0.5913 - ETA: 12:31 - 194ms/step
step 1150/5005 [=====>........................] - loss: 2.8705 - acc_top1: 0.3433 - acc_top5: 0.5918 - ETA: 12:29 - 194ms/step
step 1160/5005 [=====>........................] - loss: 2.9987 - acc_top1: 0.3438 - acc_top5: 0.5926 - ETA: 12:29 - 195ms/step
step 1170/5005 [======>.......................] - loss: 2.6001 - acc_top1: 0.3442 - acc_top5: 0.5931 - ETA: 12:25 - 194ms/step
step 1180/5005 [======>.......................] - loss: 2.5216 - acc_top1: 0.3450 - acc_top5: 0.5940 - ETA: 12:24 - 195ms/step
step 1190/5005 [======>.......................] - loss: 2.0699 - acc_top1: 0.3455 - acc_top5: 0.5946 - ETA: 12:23 - 195ms/step
step 1200/5005 [======>.......................] - loss: 2.8659 - acc_top1: 0.3459 - acc_top5: 0.5952 - ETA: 12:22 - 195ms/step
step 1210/5005 [======>.......................] - loss: 3.4581 - acc_top1: 0.3465 - acc_top5: 0.5957 - ETA: 12:19 - 195ms/step
step 1220/5005 [======>.......................] - loss: 2.3413 - acc_top1: 0.3471 - acc_top5: 0.5963 - ETA: 12:18 - 195ms/step
step 1230/5005 [======>.......................] - loss: 2.4186 - acc_top1: 0.3478 - acc_top5: 0.5970 - ETA: 12:15 - 195ms/step
step 1240/5005 [======>.......................] - loss: 2.5342 - acc_top1: 0.3483 - acc_top5: 0.5978 - ETA: 12:14 - 195ms/step
step 1250/5005 [======>.......................] - loss: 2.5562 - acc_top1: 0.3491 - acc_top5: 0.5985 - ETA: 12:11 - 195ms/step
step 1260/5005 [======>.......................] - loss: 2.6468 - acc_top1: 0.3496 - acc_top5: 0.5991 - ETA: 12:08 - 195ms/step
step 1270/5005 [======>.......................] - loss: 2.8273 - acc_top1: 0.3503 - acc_top5: 0.5999 - ETA: 12:07 - 195ms/step
step 1280/5005 [======>.......................] - loss: 2.8838 - acc_top1: 0.3506 - acc_top5: 0.6005 - ETA: 12:04 - 195ms/step
step 1290/5005 [======>.......................] - loss: 2.6927 - acc_top1: 0.3512 - acc_top5: 0.6009 - ETA: 12:02 - 195ms/step
step 1300/5005 [======>.......................] - loss: 2.6445 - acc_top1: 0.3517 - acc_top5: 0.6015 - ETA: 12:00 - 194ms/step
step 1310/5005 [======>.......................] - loss: 2.4317 - acc_top1: 0.3521 - acc_top5: 0.6020 - ETA: 11:57 - 194ms/step
step 1320/5005 [======>.......................] - loss: 2.5294 - acc_top1: 0.3526 - acc_top5: 0.6027 - ETA: 11:55 - 194ms/step
step 1330/5005 [======>.......................] - loss: 2.6981 - acc_top1: 0.3532 - acc_top5: 0.6033 - ETA: 11:52 - 194ms/step
step 1340/5005 [=======>......................] - loss: 2.2223 - acc_top1: 0.3542 - acc_top5: 0.6043 - ETA: 11:52 - 194ms/step
step 1350/5005 [=======>......................] - loss: 3.2397 - acc_top1: 0.3548 - acc_top5: 0.6048 - ETA: 11:50 - 194ms/step
step 1360/5005 [=======>......................] - loss: 2.6328 - acc_top1: 0.3551 - acc_top5: 0.6051 - ETA: 11:47 - 194ms/step
step 1370/5005 [=======>......................] - loss: 2.2138 - acc_top1: 0.3557 - acc_top5: 0.6057 - ETA: 11:45 - 194ms/step
step 1380/5005 [=======>......................] - loss: 2.0484 - acc_top1: 0.3565 - acc_top5: 0.6064 - ETA: 11:42 - 194ms/step
step 1390/5005 [=======>......................] - loss: 2.0739 - acc_top1: 0.3574 - acc_top5: 0.6072 - ETA: 11:38 - 193ms/step
step 1400/5005 [=======>......................] - loss: 2.4631 - acc_top1: 0.3580 - acc_top5: 0.6080 - ETA: 11:35 - 193ms/step
step 1410/5005 [=======>......................] - loss: 2.4890 - acc_top1: 0.3587 - acc_top5: 0.6084 - ETA: 11:33 - 193ms/step
step 1420/5005 [=======>......................] - loss: 2.4767 - acc_top1: 0.3593 - acc_top5: 0.6088 - ETA: 11:31 - 193ms/step
step 1430/5005 [=======>......................] - loss: 2.8734 - acc_top1: 0.3597 - acc_top5: 0.6093 - ETA: 11:28 - 193ms/step
step 1440/5005 [=======>......................] - loss: 2.9314 - acc_top1: 0.3602 - acc_top5: 0.6097 - ETA: 11:26 - 193ms/step
step 1450/5005 [=======>......................] - loss: 2.4359 - acc_top1: 0.3607 - acc_top5: 0.6104 - ETA: 11:24 - 193ms/step
step 1460/5005 [=======>......................] - loss: 2.8815 - acc_top1: 0.3611 - acc_top5: 0.6108 - ETA: 11:21 - 192ms/step
step 1470/5005 [=======>......................] - loss: 2.2249 - acc_top1: 0.3617 - acc_top5: 0.6113 - ETA: 11:21 - 193ms/step
step 1480/5005 [=======>......................] - loss: 2.8477 - acc_top1: 0.3620 - acc_top5: 0.6117 - ETA: 11:18 - 193ms/step
step 1490/5005 [=======>......................] - loss: 2.3764 - acc_top1: 0.3625 - acc_top5: 0.6122 - ETA: 11:15 - 192ms/step
step 1500/5005 [=======>......................] - loss: 2.5315 - acc_top1: 0.3630 - acc_top5: 0.6127 - ETA: 11:13 - 192ms/step
step 1510/5005 [========>.....................] - loss: 2.1764 - acc_top1: 0.3636 - acc_top5: 0.6133 - ETA: 11:12 - 192ms/step
step 1520/5005 [========>.....................] - loss: 2.4774 - acc_top1: 0.3640 - acc_top5: 0.6137 - ETA: 11:08 - 192ms/step
step 1530/5005 [========>.....................] - loss: 2.8046 - acc_top1: 0.3644 - acc_top5: 0.6141 - ETA: 11:07 - 192ms/step
step 1540/5005 [========>.....................] - loss: 2.6407 - acc_top1: 0.3648 - acc_top5: 0.6146 - ETA: 11:04 - 192ms/step
step 1550/5005 [========>.....................] - loss: 2.3508 - acc_top1: 0.3653 - acc_top5: 0.6152 - ETA: 11:03 - 192ms/step
step 1560/5005 [========>.....................] - loss: 2.3242 - acc_top1: 0.3657 - acc_top5: 0.6158 - ETA: 11:00 - 192ms/step
step 1570/5005 [========>.....................] - loss: 2.2052 - acc_top1: 0.3662 - acc_top5: 0.6161 - ETA: 11:00 - 192ms/step
step 1580/5005 [========>.....................] - loss: 2.5260 - acc_top1: 0.3666 - acc_top5: 0.6165 - ETA: 10:57 - 192ms/step
step 1590/5005 [========>.....................] - loss: 2.4911 - acc_top1: 0.3671 - acc_top5: 0.6171 - ETA: 10:54 - 192ms/step
step 1600/5005 [========>.....................] - loss: 2.5005 - acc_top1: 0.3675 - acc_top5: 0.6175 - ETA: 10:52 - 192ms/step
step 1610/5005 [========>.....................] - loss: 2.9531 - acc_top1: 0.3681 - acc_top5: 0.6180 - ETA: 10:49 - 191ms/step
step 1620/5005 [========>.....................] - loss: 2.7063 - acc_top1: 0.3686 - acc_top5: 0.6184 - ETA: 10:48 - 192ms/step
step 1630/5005 [========>.....................] - loss: 2.6359 - acc_top1: 0.3690 - acc_top5: 0.6188 - ETA: 10:45 - 191ms/step
step 1640/5005 [========>.....................] - loss: 1.7187 - acc_top1: 0.3696 - acc_top5: 0.6193 - ETA: 10:43 - 191ms/step
step 1650/5005 [========>.....................] - loss: 2.6842 - acc_top1: 0.3700 - acc_top5: 0.6198 - ETA: 10:42 - 191ms/step
step 1660/5005 [========>.....................] - loss: 2.2971 - acc_top1: 0.3704 - acc_top5: 0.6201 - ETA: 10:40 - 191ms/step
step 1670/5005 [=========>....................] - loss: 2.1143 - acc_top1: 0.3708 - acc_top5: 0.6204 - ETA: 10:39 - 192ms/step
step 1680/5005 [=========>....................] - loss: 2.3223 - acc_top1: 0.3714 - acc_top5: 0.6209 - ETA: 10:36 - 191ms/step
step 1690/5005 [=========>....................] - loss: 2.8670 - acc_top1: 0.3718 - acc_top5: 0.6213 - ETA: 10:35 - 192ms/step
step 1700/5005 [=========>....................] - loss: 2.3398 - acc_top1: 0.3722 - acc_top5: 0.6218 - ETA: 10:33 - 192ms/step
step 1710/5005 [=========>....................] - loss: 2.4394 - acc_top1: 0.3726 - acc_top5: 0.6221 - ETA: 10:30 - 191ms/step
step 1720/5005 [=========>....................] - loss: 2.2717 - acc_top1: 0.3730 - acc_top5: 0.6225 - ETA: 10:28 - 191ms/step
step 1730/5005 [=========>....................] - loss: 2.7069 - acc_top1: 0.3736 - acc_top5: 0.6229 - ETA: 10:26 - 191ms/step
step 1740/5005 [=========>....................] - loss: 2.4108 - acc_top1: 0.3738 - acc_top5: 0.6233 - ETA: 10:23 - 191ms/step
step 1750/5005 [=========>....................] - loss: 2.6409 - acc_top1: 0.3744 - acc_top5: 0.6238 - ETA: 10:22 - 191ms/step
step 1760/5005 [=========>....................] - loss: 1.9782 - acc_top1: 0.3750 - acc_top5: 0.6243 - ETA: 10:20 - 191ms/step
step 1770/5005 [=========>....................] - loss: 2.5090 - acc_top1: 0.3754 - acc_top5: 0.6246 - ETA: 10:19 - 191ms/step
step 1780/5005 [=========>....................] - loss: 2.0337 - acc_top1: 0.3758 - acc_top5: 0.6251 - ETA: 10:16 - 191ms/step
step 1790/5005 [=========>....................] - loss: 2.5060 - acc_top1: 0.3763 - acc_top5: 0.6257 - ETA: 10:14 - 191ms/step
step 1800/5005 [=========>....................] - loss: 2.0773 - acc_top1: 0.3767 - acc_top5: 0.6261 - ETA: 10:12 - 191ms/step
step 1810/5005 [=========>....................] - loss: 2.1072 - acc_top1: 0.3772 - acc_top5: 0.6266 - ETA: 10:10 - 191ms/step
step 1820/5005 [=========>....................] - loss: 2.1905 - acc_top1: 0.3776 - acc_top5: 0.6270 - ETA: 10:07 - 191ms/step
step 1830/5005 [=========>....................] - loss: 2.2720 - acc_top1: 0.3780 - acc_top5: 0.6273 - ETA: 10:05 - 191ms/step
step 1840/5005 [==========>...................] - loss: 2.1696 - acc_top1: 0.3783 - acc_top5: 0.6278 - ETA: 10:04 - 191ms/step
step 1850/5005 [==========>...................] - loss: 2.1422 - acc_top1: 0.3787 - acc_top5: 0.6281 - ETA: 10:01 - 191ms/step
step 1860/5005 [==========>...................] - loss: 2.4204 - acc_top1: 0.3790 - acc_top5: 0.6285 - ETA: 9:59 - 191ms/step 
step 1870/5005 [==========>...................] - loss: 2.2848 - acc_top1: 0.3795 - acc_top5: 0.6290 - ETA: 9:56 - 190ms/step
step 1880/5005 [==========>...................] - loss: 2.2410 - acc_top1: 0.3799 - acc_top5: 0.6294 - ETA: 9:54 - 190ms/step
step 1890/5005 [==========>...................] - loss: 2.1435 - acc_top1: 0.3803 - acc_top5: 0.6300 - ETA: 9:52 - 190ms/step
step 1900/5005 [==========>...................] - loss: 2.5143 - acc_top1: 0.3805 - acc_top5: 0.6303 - ETA: 9:49 - 190ms/step
step 1910/5005 [==========>...................] - loss: 2.4100 - acc_top1: 0.3806 - acc_top5: 0.6306 - ETA: 9:47 - 190ms/step
step 1920/5005 [==========>...................] - loss: 2.5479 - acc_top1: 0.3809 - acc_top5: 0.6308 - ETA: 9:44 - 189ms/step
step 1930/5005 [==========>...................] - loss: 2.4021 - acc_top1: 0.3814 - acc_top5: 0.6312 - ETA: 9:43 - 190ms/step
step 1940/5005 [==========>...................] - loss: 2.7449 - acc_top1: 0.3817 - acc_top5: 0.6316 - ETA: 9:41 - 190ms/step
step 1950/5005 [==========>...................] - loss: 2.2092 - acc_top1: 0.3821 - acc_top5: 0.6319 - ETA: 9:38 - 189ms/step
step 1960/5005 [==========>...................] - loss: 2.5220 - acc_top1: 0.3824 - acc_top5: 0.6322 - ETA: 9:36 - 189ms/step
step 1970/5005 [==========>...................] - loss: 2.2655 - acc_top1: 0.3827 - acc_top5: 0.6326 - ETA: 9:33 - 189ms/step
step 1980/5005 [==========>...................] - loss: 2.7006 - acc_top1: 0.3828 - acc_top5: 0.6327 - ETA: 9:31 - 189ms/step
step 1990/5005 [==========>...................] - loss: 1.7792 - acc_top1: 0.3833 - acc_top5: 0.6333 - ETA: 9:29 - 189ms/step
step 2000/5005 [==========>...................] - loss: 1.9211 - acc_top1: 0.3839 - acc_top5: 0.6338 - ETA: 9:26 - 189ms/step
step 2010/5005 [===========>..................] - loss: 2.6299 - acc_top1: 0.3843 - acc_top5: 0.6341 - ETA: 9:24 - 188ms/step
step 2020/5005 [===========>..................] - loss: 2.0870 - acc_top1: 0.3847 - acc_top5: 0.6344 - ETA: 9:22 - 188ms/step
step 2030/5005 [===========>..................] - loss: 1.7586 - acc_top1: 0.3851 - acc_top5: 0.6349 - ETA: 9:19 - 188ms/step
step 2040/5005 [===========>..................] - loss: 2.3129 - acc_top1: 0.3855 - acc_top5: 0.6353 - ETA: 9:17 - 188ms/step
step 2050/5005 [===========>..................] - loss: 2.1154 - acc_top1: 0.3858 - acc_top5: 0.6357 - ETA: 9:14 - 188ms/step
step 2060/5005 [===========>..................] - loss: 2.6242 - acc_top1: 0.3861 - acc_top5: 0.6358 - ETA: 9:13 - 188ms/step
step 2070/5005 [===========>..................] - loss: 2.7662 - acc_top1: 0.3864 - acc_top5: 0.6362 - ETA: 9:10 - 188ms/step
step 2080/5005 [===========>..................] - loss: 2.6790 - acc_top1: 0.3866 - acc_top5: 0.6364 - ETA: 9:09 - 188ms/step
step 2090/5005 [===========>..................] - loss: 1.9681 - acc_top1: 0.3871 - acc_top5: 0.6366 - ETA: 9:06 - 188ms/step
step 2100/5005 [===========>..................] - loss: 2.9406 - acc_top1: 0.3873 - acc_top5: 0.6368 - ETA: 9:04 - 187ms/step
step 2110/5005 [===========>..................] - loss: 3.0199 - acc_top1: 0.3875 - acc_top5: 0.6371 - ETA: 9:02 - 187ms/step
step 2120/5005 [===========>..................] - loss: 3.0713 - acc_top1: 0.3878 - acc_top5: 0.6374 - ETA: 9:01 - 188ms/step
step 2130/5005 [===========>..................] - loss: 2.5121 - acc_top1: 0.3880 - acc_top5: 0.6377 - ETA: 8:58 - 187ms/step
step 2140/5005 [===========>..................] - loss: 2.3133 - acc_top1: 0.3883 - acc_top5: 0.6380 - ETA: 8:55 - 187ms/step
step 2150/5005 [===========>..................] - loss: 2.8221 - acc_top1: 0.3888 - acc_top5: 0.6384 - ETA: 8:54 - 187ms/step
step 2160/5005 [===========>..................] - loss: 2.5687 - acc_top1: 0.3890 - acc_top5: 0.6387 - ETA: 8:52 - 187ms/step
step 2170/5005 [============>.................] - loss: 2.3668 - acc_top1: 0.3892 - acc_top5: 0.6390 - ETA: 8:50 - 187ms/step
step 2180/5005 [============>.................] - loss: 2.9422 - acc_top1: 0.3895 - acc_top5: 0.6393 - ETA: 8:49 - 187ms/step
step 2190/5005 [============>.................] - loss: 3.0033 - acc_top1: 0.3898 - acc_top5: 0.6396 - ETA: 8:46 - 187ms/step
step 2200/5005 [============>.................] - loss: 2.2557 - acc_top1: 0.3902 - acc_top5: 0.6399 - ETA: 8:45 - 187ms/step
step 2210/5005 [============>.................] - loss: 2.4130 - acc_top1: 0.3907 - acc_top5: 0.6403 - ETA: 8:42 - 187ms/step
step 2220/5005 [============>.................] - loss: 2.0658 - acc_top1: 0.3910 - acc_top5: 0.6406 - ETA: 8:41 - 187ms/step
step 2230/5005 [============>.................] - loss: 2.1563 - acc_top1: 0.3914 - acc_top5: 0.6411 - ETA: 8:39 - 187ms/step
step 2240/5005 [============>.................] - loss: 2.6195 - acc_top1: 0.3917 - acc_top5: 0.6415 - ETA: 8:37 - 187ms/step
step 2250/5005 [============>.................] - loss: 2.3843 - acc_top1: 0.3921 - acc_top5: 0.6418 - ETA: 8:35 - 187ms/step
step 2260/5005 [============>.................] - loss: 2.5244 - acc_top1: 0.3925 - acc_top5: 0.6422 - ETA: 8:34 - 187ms/step
step 2270/5005 [============>.................] - loss: 2.1123 - acc_top1: 0.3928 - acc_top5: 0.6425 - ETA: 8:32 - 187ms/step
step 2280/5005 [============>.................] - loss: 2.8664 - acc_top1: 0.3931 - acc_top5: 0.6429 - ETA: 8:30 - 187ms/step
step 2290/5005 [============>.................] - loss: 2.1633 - acc_top1: 0.3934 - acc_top5: 0.6433 - ETA: 8:28 - 187ms/step
step 2300/5005 [============>.................] - loss: 1.6840 - acc_top1: 0.3937 - acc_top5: 0.6435 - ETA: 8:25 - 187ms/step
step 2310/5005 [============>.................] - loss: 2.4639 - acc_top1: 0.3941 - acc_top5: 0.6439 - ETA: 8:24 - 187ms/step
step 2320/5005 [============>.................] - loss: 2.0081 - acc_top1: 0.3945 - acc_top5: 0.6443 - ETA: 8:21 - 187ms/step
step 2330/5005 [============>.................] - loss: 1.7960 - acc_top1: 0.3948 - acc_top5: 0.6447 - ETA: 8:19 - 187ms/step
step 2340/5005 [=============>................] - loss: 2.2776 - acc_top1: 0.3952 - acc_top5: 0.6451 - ETA: 8:17 - 187ms/step
step 2350/5005 [=============>................] - loss: 2.3588 - acc_top1: 0.3954 - acc_top5: 0.6453 - ETA: 8:15 - 187ms/step
step 2360/5005 [=============>................] - loss: 2.5106 - acc_top1: 0.3957 - acc_top5: 0.6456 - ETA: 8:12 - 186ms/step
step 2370/5005 [=============>................] - loss: 2.3660 - acc_top1: 0.3960 - acc_top5: 0.6458 - ETA: 8:10 - 186ms/step
step 2380/5005 [=============>................] - loss: 2.5048 - acc_top1: 0.3962 - acc_top5: 0.6460 - ETA: 8:09 - 186ms/step
step 2390/5005 [=============>................] - loss: 1.7393 - acc_top1: 0.3966 - acc_top5: 0.6464 - ETA: 8:06 - 186ms/step
step 2400/5005 [=============>................] - loss: 2.4224 - acc_top1: 0.3970 - acc_top5: 0.6468 - ETA: 8:04 - 186ms/step
step 2410/5005 [=============>................] - loss: 2.6698 - acc_top1: 0.3973 - acc_top5: 0.6472 - ETA: 8:02 - 186ms/step
step 2420/5005 [=============>................] - loss: 2.1901 - acc_top1: 0.3976 - acc_top5: 0.6475 - ETA: 8:00 - 186ms/step
step 2430/5005 [=============>................] - loss: 2.2889 - acc_top1: 0.3979 - acc_top5: 0.6478 - ETA: 7:58 - 186ms/step
step 2440/5005 [=============>................] - loss: 2.3205 - acc_top1: 0.3983 - acc_top5: 0.6481 - ETA: 7:56 - 186ms/step
step 2450/5005 [=============>................] - loss: 2.3704 - acc_top1: 0.3985 - acc_top5: 0.6482 - ETA: 7:54 - 186ms/step
step 2460/5005 [=============>................] - loss: 2.2646 - acc_top1: 0.3987 - acc_top5: 0.6484 - ETA: 7:51 - 185ms/step
step 2470/5005 [=============>................] - loss: 2.4516 - acc_top1: 0.3990 - acc_top5: 0.6487 - ETA: 7:49 - 185ms/step
step 2480/5005 [=============>................] - loss: 2.5303 - acc_top1: 0.3995 - acc_top5: 0.6490 - ETA: 7:47 - 185ms/step
step 2490/5005 [=============>................] - loss: 2.5395 - acc_top1: 0.3998 - acc_top5: 0.6492 - ETA: 7:45 - 185ms/step
step 2500/5005 [=============>................] - loss: 2.0161 - acc_top1: 0.4001 - acc_top5: 0.6495 - ETA: 7:42 - 185ms/step
step 2510/5005 [==============>...............] - loss: 2.4376 - acc_top1: 0.4002 - acc_top5: 0.6497 - ETA: 7:41 - 185ms/step
step 2520/5005 [==============>...............] - loss: 2.8276 - acc_top1: 0.4005 - acc_top5: 0.6500 - ETA: 7:39 - 185ms/step
step 2530/5005 [==============>...............] - loss: 2.3251 - acc_top1: 0.4007 - acc_top5: 0.6503 - ETA: 7:37 - 185ms/step
step 2540/5005 [==============>...............] - loss: 2.0758 - acc_top1: 0.4010 - acc_top5: 0.6505 - ETA: 7:35 - 185ms/step
step 2550/5005 [==============>...............] - loss: 2.5207 - acc_top1: 0.4013 - acc_top5: 0.6509 - ETA: 7:34 - 185ms/step
step 2560/5005 [==============>...............] - loss: 2.0931 - acc_top1: 0.4016 - acc_top5: 0.6512 - ETA: 7:32 - 185ms/step
step 2570/5005 [==============>...............] - loss: 2.9364 - acc_top1: 0.4018 - acc_top5: 0.6514 - ETA: 7:30 - 185ms/step
step 2580/5005 [==============>...............] - loss: 2.5157 - acc_top1: 0.4020 - acc_top5: 0.6516 - ETA: 7:27 - 185ms/step
step 2590/5005 [==============>...............] - loss: 2.1054 - acc_top1: 0.4022 - acc_top5: 0.6519 - ETA: 7:26 - 185ms/step
step 2600/5005 [==============>...............] - loss: 2.8748 - acc_top1: 0.4024 - acc_top5: 0.6521 - ETA: 7:24 - 185ms/step
step 2610/5005 [==============>...............] - loss: 2.1942 - acc_top1: 0.4026 - acc_top5: 0.6524 - ETA: 7:22 - 185ms/step
step 2620/5005 [==============>...............] - loss: 2.3214 - acc_top1: 0.4029 - acc_top5: 0.6527 - ETA: 7:20 - 185ms/step
step 2630/5005 [==============>...............] - loss: 2.2852 - acc_top1: 0.4032 - acc_top5: 0.6530 - ETA: 7:18 - 185ms/step
step 2640/5005 [==============>...............] - loss: 2.2208 - acc_top1: 0.4034 - acc_top5: 0.6534 - ETA: 7:16 - 185ms/step
step 2650/5005 [==============>...............] - loss: 1.8760 - acc_top1: 0.4037 - acc_top5: 0.6537 - ETA: 7:14 - 185ms/step
step 2660/5005 [==============>...............] - loss: 2.0698 - acc_top1: 0.4041 - acc_top5: 0.6539 - ETA: 7:12 - 184ms/step
step 2670/5005 [===============>..............] - loss: 2.6301 - acc_top1: 0.4044 - acc_top5: 0.6542 - ETA: 7:10 - 184ms/step
step 2680/5005 [===============>..............] - loss: 3.0211 - acc_top1: 0.4046 - acc_top5: 0.6544 - ETA: 7:08 - 184ms/step
step 2690/5005 [===============>..............] - loss: 2.2903 - acc_top1: 0.4050 - acc_top5: 0.6547 - ETA: 7:06 - 184ms/step
step 2700/5005 [===============>..............] - loss: 2.3301 - acc_top1: 0.4053 - acc_top5: 0.6550 - ETA: 7:04 - 184ms/step
step 2710/5005 [===============>..............] - loss: 2.2223 - acc_top1: 0.4056 - acc_top5: 0.6553 - ETA: 7:02 - 184ms/step
step 2720/5005 [===============>..............] - loss: 1.9617 - acc_top1: 0.4058 - acc_top5: 0.6555 - ETA: 7:00 - 184ms/step
step 2730/5005 [===============>..............] - loss: 2.2325 - acc_top1: 0.4060 - acc_top5: 0.6557 - ETA: 6:58 - 184ms/step
step 2740/5005 [===============>..............] - loss: 2.4252 - acc_top1: 0.4064 - acc_top5: 0.6560 - ETA: 6:56 - 184ms/step
step 2750/5005 [===============>..............] - loss: 2.4872 - acc_top1: 0.4066 - acc_top5: 0.6563 - ETA: 6:54 - 184ms/step
step 2760/5005 [===============>..............] - loss: 1.8928 - acc_top1: 0.4070 - acc_top5: 0.6566 - ETA: 6:52 - 184ms/step
step 2770/5005 [===============>..............] - loss: 1.9044 - acc_top1: 0.4072 - acc_top5: 0.6567 - ETA: 6:50 - 184ms/step
step 2780/5005 [===============>..............] - loss: 2.1364 - acc_top1: 0.4075 - acc_top5: 0.6570 - ETA: 6:49 - 184ms/step
step 2790/5005 [===============>..............] - loss: 2.7386 - acc_top1: 0.4078 - acc_top5: 0.6572 - ETA: 6:47 - 184ms/step
step 2800/5005 [===============>..............] - loss: 2.2293 - acc_top1: 0.4080 - acc_top5: 0.6573 - ETA: 6:44 - 184ms/step
step 2810/5005 [===============>..............] - loss: 2.3118 - acc_top1: 0.4083 - acc_top5: 0.6576 - ETA: 6:43 - 184ms/step
step 2820/5005 [===============>..............] - loss: 1.9504 - acc_top1: 0.4086 - acc_top5: 0.6580 - ETA: 6:41 - 184ms/step
step 2830/5005 [===============>..............] - loss: 2.4499 - acc_top1: 0.4088 - acc_top5: 0.6582 - ETA: 6:39 - 184ms/step
step 2840/5005 [================>.............] - loss: 1.9171 - acc_top1: 0.4092 - acc_top5: 0.6585 - ETA: 6:37 - 184ms/step
step 2850/5005 [================>.............] - loss: 1.7853 - acc_top1: 0.4094 - acc_top5: 0.6588 - ETA: 6:35 - 184ms/step
step 2860/5005 [================>.............] - loss: 1.8592 - acc_top1: 0.4096 - acc_top5: 0.6590 - ETA: 6:33 - 183ms/step
step 2870/5005 [================>.............] - loss: 2.3757 - acc_top1: 0.4098 - acc_top5: 0.6592 - ETA: 6:31 - 183ms/step
step 2880/5005 [================>.............] - loss: 2.1509 - acc_top1: 0.4100 - acc_top5: 0.6594 - ETA: 6:29 - 183ms/step
step 2890/5005 [================>.............] - loss: 2.8290 - acc_top1: 0.4101 - acc_top5: 0.6595 - ETA: 6:27 - 183ms/step
step 2900/5005 [================>.............] - loss: 2.4957 - acc_top1: 0.4103 - acc_top5: 0.6596 - ETA: 6:25 - 183ms/step
step 2910/5005 [================>.............] - loss: 2.4227 - acc_top1: 0.4105 - acc_top5: 0.6598 - ETA: 6:24 - 183ms/step
step 2920/5005 [================>.............] - loss: 1.8375 - acc_top1: 0.4109 - acc_top5: 0.6601 - ETA: 6:22 - 183ms/step
step 2930/5005 [================>.............] - loss: 2.6275 - acc_top1: 0.4111 - acc_top5: 0.6602 - ETA: 6:20 - 183ms/step
step 2940/5005 [================>.............] - loss: 2.4900 - acc_top1: 0.4112 - acc_top5: 0.6604 - ETA: 6:18 - 183ms/step
step 2950/5005 [================>.............] - loss: 2.5432 - acc_top1: 0.4114 - acc_top5: 0.6606 - ETA: 6:17 - 183ms/step
step 2960/5005 [================>.............] - loss: 2.5748 - acc_top1: 0.4117 - acc_top5: 0.6607 - ETA: 6:15 - 183ms/step
step 2970/5005 [================>.............] - loss: 2.2809 - acc_top1: 0.4119 - acc_top5: 0.6608 - ETA: 6:13 - 184ms/step
step 2980/5005 [================>.............] - loss: 2.3638 - acc_top1: 0.4122 - acc_top5: 0.6610 - ETA: 6:11 - 184ms/step
step 2990/5005 [================>.............] - loss: 1.8256 - acc_top1: 0.4125 - acc_top5: 0.6613 - ETA: 6:10 - 184ms/step
step 3000/5005 [================>.............] - loss: 2.3643 - acc_top1: 0.4127 - acc_top5: 0.6616 - ETA: 6:08 - 184ms/step
step 3010/5005 [=================>............] - loss: 2.3075 - acc_top1: 0.4129 - acc_top5: 0.6619 - ETA: 6:06 - 184ms/step
step 3020/5005 [=================>............] - loss: 2.2968 - acc_top1: 0.4131 - acc_top5: 0.6621 - ETA: 6:04 - 184ms/step
step 3030/5005 [=================>............] - loss: 2.3331 - acc_top1: 0.4133 - acc_top5: 0.6624 - ETA: 6:02 - 183ms/step
step 3040/5005 [=================>............] - loss: 2.2574 - acc_top1: 0.4135 - acc_top5: 0.6625 - ETA: 6:00 - 184ms/step
step 3050/5005 [=================>............] - loss: 2.5945 - acc_top1: 0.4139 - acc_top5: 0.6628 - ETA: 5:58 - 184ms/step
step 3060/5005 [=================>............] - loss: 2.1892 - acc_top1: 0.4140 - acc_top5: 0.6631 - ETA: 5:56 - 183ms/step
step 3070/5005 [=================>............] - loss: 1.8887 - acc_top1: 0.4142 - acc_top5: 0.6632 - ETA: 5:54 - 183ms/step
step 3080/5005 [=================>............] - loss: 2.5032 - acc_top1: 0.4145 - acc_top5: 0.6634 - ETA: 5:53 - 183ms/step
step 3090/5005 [=================>............] - loss: 1.7925 - acc_top1: 0.4147 - acc_top5: 0.6636 - ETA: 5:51 - 183ms/step
step 3100/5005 [=================>............] - loss: 1.8559 - acc_top1: 0.4151 - acc_top5: 0.6639 - ETA: 5:49 - 183ms/step
step 3110/5005 [=================>............] - loss: 2.4026 - acc_top1: 0.4153 - acc_top5: 0.6640 - ETA: 5:47 - 183ms/step
step 3120/5005 [=================>............] - loss: 2.3024 - acc_top1: 0.4154 - acc_top5: 0.6642 - ETA: 5:45 - 183ms/step
step 3130/5005 [=================>............] - loss: 2.1926 - acc_top1: 0.4155 - acc_top5: 0.6643 - ETA: 5:43 - 183ms/step
step 3140/5005 [=================>............] - loss: 2.3494 - acc_top1: 0.4158 - acc_top5: 0.6645 - ETA: 5:42 - 183ms/step
step 3150/5005 [=================>............] - loss: 1.9788 - acc_top1: 0.4160 - acc_top5: 0.6647 - ETA: 5:40 - 184ms/step
step 3160/5005 [=================>............] - loss: 1.8830 - acc_top1: 0.4161 - acc_top5: 0.6649 - ETA: 5:38 - 184ms/step
step 3170/5005 [==================>...........] - loss: 2.1941 - acc_top1: 0.4163 - acc_top5: 0.6650 - ETA: 5:36 - 184ms/step
step 3180/5005 [==================>...........] - loss: 2.5542 - acc_top1: 0.4165 - acc_top5: 0.6651 - ETA: 5:35 - 184ms/step
step 3190/5005 [==================>...........] - loss: 2.3614 - acc_top1: 0.4166 - acc_top5: 0.6653 - ETA: 5:33 - 184ms/step
step 3200/5005 [==================>...........] - loss: 2.4635 - acc_top1: 0.4168 - acc_top5: 0.6655 - ETA: 5:31 - 184ms/step
step 3210/5005 [==================>...........] - loss: 1.8895 - acc_top1: 0.4171 - acc_top5: 0.6657 - ETA: 5:30 - 184ms/step
step 3220/5005 [==================>...........] - loss: 2.2520 - acc_top1: 0.4173 - acc_top5: 0.6659 - ETA: 5:28 - 184ms/step
step 3230/5005 [==================>...........] - loss: 2.3141 - acc_top1: 0.4175 - acc_top5: 0.6661 - ETA: 5:26 - 184ms/step
step 3240/5005 [==================>...........] - loss: 2.4658 - acc_top1: 0.4177 - acc_top5: 0.6663 - ETA: 5:24 - 184ms/step
step 3250/5005 [==================>...........] - loss: 1.6738 - acc_top1: 0.4179 - acc_top5: 0.6664 - ETA: 5:23 - 184ms/step
step 3260/5005 [==================>...........] - loss: 2.4877 - acc_top1: 0.4181 - acc_top5: 0.6666 - ETA: 5:21 - 184ms/step
step 3270/5005 [==================>...........] - loss: 2.0502 - acc_top1: 0.4183 - acc_top5: 0.6668 - ETA: 5:19 - 184ms/step
step 3280/5005 [==================>...........] - loss: 2.1824 - acc_top1: 0.4184 - acc_top5: 0.6669 - ETA: 5:17 - 184ms/step
step 3290/5005 [==================>...........] - loss: 2.5963 - acc_top1: 0.4186 - acc_top5: 0.6671 - ETA: 5:15 - 184ms/step
step 3300/5005 [==================>...........] - loss: 2.7166 - acc_top1: 0.4188 - acc_top5: 0.6674 - ETA: 5:13 - 184ms/step
step 3310/5005 [==================>...........] - loss: 3.0918 - acc_top1: 0.4191 - acc_top5: 0.6676 - ETA: 5:11 - 184ms/step
step 3320/5005 [==================>...........] - loss: 2.0393 - acc_top1: 0.4193 - acc_top5: 0.6679 - ETA: 5:09 - 184ms/step
step 3330/5005 [==================>...........] - loss: 1.9209 - acc_top1: 0.4195 - acc_top5: 0.6680 - ETA: 5:07 - 184ms/step
step 3340/5005 [===================>..........] - loss: 2.1791 - acc_top1: 0.4197 - acc_top5: 0.6683 - ETA: 5:05 - 184ms/step
step 3350/5005 [===================>..........] - loss: 1.9980 - acc_top1: 0.4198 - acc_top5: 0.6686 - ETA: 5:04 - 184ms/step
step 3360/5005 [===================>..........] - loss: 2.0302 - acc_top1: 0.4200 - acc_top5: 0.6688 - ETA: 5:02 - 184ms/step
step 3370/5005 [===================>..........] - loss: 2.3917 - acc_top1: 0.4202 - acc_top5: 0.6690 - ETA: 5:00 - 184ms/step
step 3380/5005 [===================>..........] - loss: 2.3533 - acc_top1: 0.4203 - acc_top5: 0.6692 - ETA: 4:58 - 184ms/step
step 3390/5005 [===================>..........] - loss: 1.7757 - acc_top1: 0.4206 - acc_top5: 0.6695 - ETA: 4:56 - 184ms/step
step 3400/5005 [===================>..........] - loss: 2.5707 - acc_top1: 0.4208 - acc_top5: 0.6697 - ETA: 4:54 - 183ms/step
step 3410/5005 [===================>..........] - loss: 2.4669 - acc_top1: 0.4210 - acc_top5: 0.6699 - ETA: 4:52 - 183ms/step
step 3420/5005 [===================>..........] - loss: 2.0136 - acc_top1: 0.4212 - acc_top5: 0.6702 - ETA: 4:50 - 183ms/step
step 3430/5005 [===================>..........] - loss: 2.2144 - acc_top1: 0.4214 - acc_top5: 0.6703 - ETA: 4:48 - 183ms/step
step 3440/5005 [===================>..........] - loss: 2.0533 - acc_top1: 0.4216 - acc_top5: 0.6705 - ETA: 4:46 - 183ms/step
step 3450/5005 [===================>..........] - loss: 2.7646 - acc_top1: 0.4218 - acc_top5: 0.6708 - ETA: 4:45 - 183ms/step
step 3460/5005 [===================>..........] - loss: 2.6643 - acc_top1: 0.4220 - acc_top5: 0.6710 - ETA: 4:43 - 183ms/step
step 3470/5005 [===================>..........] - loss: 2.3011 - acc_top1: 0.4222 - acc_top5: 0.6711 - ETA: 4:42 - 184ms/step
step 3480/5005 [===================>..........] - loss: 2.6640 - acc_top1: 0.4224 - acc_top5: 0.6713 - ETA: 4:40 - 184ms/step
step 3490/5005 [===================>..........] - loss: 2.0440 - acc_top1: 0.4226 - acc_top5: 0.6715 - ETA: 4:38 - 184ms/step
step 3500/5005 [===================>..........] - loss: 2.5829 - acc_top1: 0.4229 - acc_top5: 0.6718 - ETA: 4:36 - 184ms/step
step 3510/5005 [====================>.........] - loss: 2.2324 - acc_top1: 0.4231 - acc_top5: 0.6720 - ETA: 4:34 - 184ms/step
step 3520/5005 [====================>.........] - loss: 2.3489 - acc_top1: 0.4233 - acc_top5: 0.6722 - ETA: 4:32 - 184ms/step
step 3530/5005 [====================>.........] - loss: 2.2842 - acc_top1: 0.4236 - acc_top5: 0.6724 - ETA: 4:30 - 184ms/step
step 3540/5005 [====================>.........] - loss: 1.9356 - acc_top1: 0.4238 - acc_top5: 0.6726 - ETA: 4:28 - 184ms/step
step 3550/5005 [====================>.........] - loss: 2.2867 - acc_top1: 0.4241 - acc_top5: 0.6728 - ETA: 4:27 - 184ms/step
step 3560/5005 [====================>.........] - loss: 2.7007 - acc_top1: 0.4242 - acc_top5: 0.6729 - ETA: 4:25 - 183ms/step
step 3570/5005 [====================>.........] - loss: 2.0808 - acc_top1: 0.4244 - acc_top5: 0.6731 - ETA: 4:23 - 183ms/step
step 3580/5005 [====================>.........] - loss: 2.8322 - acc_top1: 0.4245 - acc_top5: 0.6733 - ETA: 4:21 - 183ms/step
step 3590/5005 [====================>.........] - loss: 2.1406 - acc_top1: 0.4247 - acc_top5: 0.6735 - ETA: 4:19 - 183ms/step
step 3600/5005 [====================>.........] - loss: 2.1504 - acc_top1: 0.4247 - acc_top5: 0.6735 - ETA: 4:17 - 183ms/step
step 3610/5005 [====================>.........] - loss: 1.9624 - acc_top1: 0.4250 - acc_top5: 0.6737 - ETA: 4:15 - 183ms/step
step 3620/5005 [====================>.........] - loss: 1.8451 - acc_top1: 0.4251 - acc_top5: 0.6739 - ETA: 4:13 - 183ms/step
step 3630/5005 [====================>.........] - loss: 1.7753 - acc_top1: 0.4253 - acc_top5: 0.6741 - ETA: 4:11 - 183ms/step
step 3640/5005 [====================>.........] - loss: 1.9348 - acc_top1: 0.4255 - acc_top5: 0.6743 - ETA: 4:09 - 183ms/step
step 3650/5005 [====================>.........] - loss: 2.5922 - acc_top1: 0.4255 - acc_top5: 0.6744 - ETA: 4:07 - 183ms/step
step 3660/5005 [====================>.........] - loss: 1.5129 - acc_top1: 0.4257 - acc_top5: 0.6745 - ETA: 4:06 - 183ms/step
step 3670/5005 [====================>.........] - loss: 1.8600 - acc_top1: 0.4259 - acc_top5: 0.6748 - ETA: 4:04 - 183ms/step
step 3680/5005 [=====================>........] - loss: 2.0795 - acc_top1: 0.4262 - acc_top5: 0.6750 - ETA: 4:02 - 183ms/step
step 3690/5005 [=====================>........] - loss: 2.5027 - acc_top1: 0.4263 - acc_top5: 0.6751 - ETA: 4:00 - 183ms/step
step 3700/5005 [=====================>........] - loss: 2.3611 - acc_top1: 0.4265 - acc_top5: 0.6753 - ETA: 3:58 - 183ms/step
step 3710/5005 [=====================>........] - loss: 2.3048 - acc_top1: 0.4266 - acc_top5: 0.6754 - ETA: 3:56 - 183ms/step
step 3720/5005 [=====================>........] - loss: 2.6039 - acc_top1: 0.4267 - acc_top5: 0.6756 - ETA: 3:54 - 183ms/step
step 3730/5005 [=====================>........] - loss: 2.4038 - acc_top1: 0.4270 - acc_top5: 0.6758 - ETA: 3:52 - 183ms/step
step 3740/5005 [=====================>........] - loss: 2.0554 - acc_top1: 0.4272 - acc_top5: 0.6760 - ETA: 3:51 - 183ms/step
step 3750/5005 [=====================>........] - loss: 2.0150 - acc_top1: 0.4274 - acc_top5: 0.6762 - ETA: 3:49 - 183ms/step
step 3760/5005 [=====================>........] - loss: 2.1916 - acc_top1: 0.4276 - acc_top5: 0.6764 - ETA: 3:47 - 183ms/step
step 3770/5005 [=====================>........] - loss: 1.9030 - acc_top1: 0.4278 - acc_top5: 0.6766 - ETA: 3:45 - 183ms/step
step 3780/5005 [=====================>........] - loss: 2.2417 - acc_top1: 0.4280 - acc_top5: 0.6768 - ETA: 3:43 - 182ms/step
step 3790/5005 [=====================>........] - loss: 2.2452 - acc_top1: 0.4282 - acc_top5: 0.6770 - ETA: 3:41 - 183ms/step
step 3800/5005 [=====================>........] - loss: 2.0516 - acc_top1: 0.4284 - acc_top5: 0.6771 - ETA: 3:39 - 182ms/step
step 3810/5005 [=====================>........] - loss: 2.3199 - acc_top1: 0.4285 - acc_top5: 0.6773 - ETA: 3:38 - 183ms/step
step 3820/5005 [=====================>........] - loss: 2.2329 - acc_top1: 0.4287 - acc_top5: 0.6775 - ETA: 3:36 - 183ms/step
step 3830/5005 [=====================>........] - loss: 2.3233 - acc_top1: 0.4288 - acc_top5: 0.6777 - ETA: 3:34 - 183ms/step
step 3840/5005 [======================>.......] - loss: 2.0809 - acc_top1: 0.4289 - acc_top5: 0.6778 - ETA: 3:32 - 183ms/step
step 3850/5005 [======================>.......] - loss: 1.6767 - acc_top1: 0.4292 - acc_top5: 0.6780 - ETA: 3:31 - 183ms/step
step 3860/5005 [======================>.......] - loss: 1.7812 - acc_top1: 0.4293 - acc_top5: 0.6781 - ETA: 3:29 - 183ms/step
step 3870/5005 [======================>.......] - loss: 1.9465 - acc_top1: 0.4295 - acc_top5: 0.6783 - ETA: 3:27 - 183ms/step
step 3880/5005 [======================>.......] - loss: 2.5187 - acc_top1: 0.4297 - acc_top5: 0.6784 - ETA: 3:25 - 183ms/step
step 3890/5005 [======================>.......] - loss: 2.1461 - acc_top1: 0.4299 - acc_top5: 0.6786 - ETA: 3:23 - 183ms/step
step 3900/5005 [======================>.......] - loss: 2.0523 - acc_top1: 0.4301 - acc_top5: 0.6788 - ETA: 3:21 - 183ms/step
step 3910/5005 [======================>.......] - loss: 1.9644 - acc_top1: 0.4302 - acc_top5: 0.6789 - ETA: 3:19 - 183ms/step
step 3920/5005 [======================>.......] - loss: 2.5241 - acc_top1: 0.4304 - acc_top5: 0.6791 - ETA: 3:18 - 183ms/step
step 3930/5005 [======================>.......] - loss: 2.2763 - acc_top1: 0.4306 - acc_top5: 0.6793 - ETA: 3:16 - 183ms/step
step 3940/5005 [======================>.......] - loss: 2.3892 - acc_top1: 0.4309 - acc_top5: 0.6795 - ETA: 3:14 - 183ms/step
step 3950/5005 [======================>.......] - loss: 2.8246 - acc_top1: 0.4310 - acc_top5: 0.6797 - ETA: 3:12 - 183ms/step
step 3960/5005 [======================>.......] - loss: 2.0788 - acc_top1: 0.4311 - acc_top5: 0.6798 - ETA: 3:10 - 183ms/step
step 3970/5005 [======================>.......] - loss: 2.7623 - acc_top1: 0.4313 - acc_top5: 0.6799 - ETA: 3:09 - 183ms/step
step 3980/5005 [======================>.......] - loss: 2.4888 - acc_top1: 0.4314 - acc_top5: 0.6800 - ETA: 3:07 - 183ms/step
step 3990/5005 [======================>.......] - loss: 2.2319 - acc_top1: 0.4315 - acc_top5: 0.6801 - ETA: 3:05 - 183ms/step
step 4000/5005 [======================>.......] - loss: 2.6957 - acc_top1: 0.4316 - acc_top5: 0.6802 - ETA: 3:03 - 183ms/step
step 4010/5005 [=======================>......] - loss: 1.8329 - acc_top1: 0.4318 - acc_top5: 0.6803 - ETA: 3:01 - 183ms/step
step 4020/5005 [=======================>......] - loss: 2.3851 - acc_top1: 0.4319 - acc_top5: 0.6805 - ETA: 2:59 - 183ms/step
step 4030/5005 [=======================>......] - loss: 2.0787 - acc_top1: 0.4321 - acc_top5: 0.6806 - ETA: 2:57 - 182ms/step
step 4040/5005 [=======================>......] - loss: 2.1970 - acc_top1: 0.4323 - acc_top5: 0.6807 - ETA: 2:56 - 182ms/step
step 4050/5005 [=======================>......] - loss: 2.1528 - acc_top1: 0.4324 - acc_top5: 0.6809 - ETA: 2:54 - 182ms/step
step 4060/5005 [=======================>......] - loss: 2.0817 - acc_top1: 0.4326 - acc_top5: 0.6811 - ETA: 2:52 - 182ms/step
step 4070/5005 [=======================>......] - loss: 1.8949 - acc_top1: 0.4328 - acc_top5: 0.6813 - ETA: 2:50 - 182ms/step
step 4080/5005 [=======================>......] - loss: 1.8400 - acc_top1: 0.4330 - acc_top5: 0.6814 - ETA: 2:48 - 183ms/step
step 4090/5005 [=======================>......] - loss: 2.4295 - acc_top1: 0.4332 - acc_top5: 0.6816 - ETA: 2:46 - 182ms/step
step 4100/5005 [=======================>......] - loss: 2.2786 - acc_top1: 0.4334 - acc_top5: 0.6817 - ETA: 2:45 - 182ms/step
step 4110/5005 [=======================>......] - loss: 2.3627 - acc_top1: 0.4335 - acc_top5: 0.6819 - ETA: 2:43 - 182ms/step
step 4120/5005 [=======================>......] - loss: 2.3303 - acc_top1: 0.4337 - acc_top5: 0.6821 - ETA: 2:41 - 182ms/step
step 4130/5005 [=======================>......] - loss: 2.2095 - acc_top1: 0.4339 - acc_top5: 0.6823 - ETA: 2:39 - 182ms/step
step 4140/5005 [=======================>......] - loss: 2.2138 - acc_top1: 0.4341 - acc_top5: 0.6824 - ETA: 2:37 - 182ms/step
step 4150/5005 [=======================>......] - loss: 2.4970 - acc_top1: 0.4342 - acc_top5: 0.6825 - ETA: 2:36 - 182ms/step
step 4160/5005 [=======================>......] - loss: 2.5657 - acc_top1: 0.4345 - acc_top5: 0.6826 - ETA: 2:34 - 183ms/step
step 4170/5005 [=======================>......] - loss: 2.0379 - acc_top1: 0.4346 - acc_top5: 0.6828 - ETA: 2:32 - 182ms/step
step 4180/5005 [========================>.....] - loss: 2.5687 - acc_top1: 0.4349 - acc_top5: 0.6829 - ETA: 2:30 - 182ms/step
step 4190/5005 [========================>.....] - loss: 2.5198 - acc_top1: 0.4350 - acc_top5: 0.6831 - ETA: 2:28 - 182ms/step
step 4200/5005 [========================>.....] - loss: 1.9396 - acc_top1: 0.4352 - acc_top5: 0.6832 - ETA: 2:26 - 182ms/step
step 4210/5005 [========================>.....] - loss: 1.8457 - acc_top1: 0.4354 - acc_top5: 0.6834 - ETA: 2:24 - 182ms/step
step 4220/5005 [========================>.....] - loss: 2.0741 - acc_top1: 0.4357 - acc_top5: 0.6835 - ETA: 2:22 - 182ms/step
step 4230/5005 [========================>.....] - loss: 2.1091 - acc_top1: 0.4358 - acc_top5: 0.6837 - ETA: 2:21 - 182ms/step
step 4240/5005 [========================>.....] - loss: 2.8704 - acc_top1: 0.4359 - acc_top5: 0.6838 - ETA: 2:19 - 182ms/step
step 4250/5005 [========================>.....] - loss: 2.6009 - acc_top1: 0.4360 - acc_top5: 0.6839 - ETA: 2:17 - 182ms/step
step 4260/5005 [========================>.....] - loss: 2.3237 - acc_top1: 0.4362 - acc_top5: 0.6842 - ETA: 2:15 - 182ms/step
step 4270/5005 [========================>.....] - loss: 2.4129 - acc_top1: 0.4363 - acc_top5: 0.6843 - ETA: 2:13 - 182ms/step
step 4280/5005 [========================>.....] - loss: 2.0657 - acc_top1: 0.4365 - acc_top5: 0.6845 - ETA: 2:11 - 182ms/step
step 4290/5005 [========================>.....] - loss: 2.0518 - acc_top1: 0.4367 - acc_top5: 0.6846 - ETA: 2:10 - 182ms/step
step 4300/5005 [========================>.....] - loss: 2.0357 - acc_top1: 0.4369 - acc_top5: 0.6848 - ETA: 2:08 - 182ms/step
step 4310/5005 [========================>.....] - loss: 2.7059 - acc_top1: 0.4370 - acc_top5: 0.6849 - ETA: 2:06 - 182ms/step
step 4320/5005 [========================>.....] - loss: 2.2175 - acc_top1: 0.4370 - acc_top5: 0.6849 - ETA: 2:04 - 182ms/step
step 4330/5005 [========================>.....] - loss: 2.7538 - acc_top1: 0.4372 - acc_top5: 0.6850 - ETA: 2:02 - 182ms/step
step 4340/5005 [=========================>....] - loss: 2.2010 - acc_top1: 0.4374 - acc_top5: 0.6851 - ETA: 2:00 - 182ms/step
step 4350/5005 [=========================>....] - loss: 1.5407 - acc_top1: 0.4376 - acc_top5: 0.6853 - ETA: 1:59 - 182ms/step
step 4360/5005 [=========================>....] - loss: 2.5004 - acc_top1: 0.4377 - acc_top5: 0.6855 - ETA: 1:57 - 182ms/step
step 4370/5005 [=========================>....] - loss: 2.0870 - acc_top1: 0.4378 - acc_top5: 0.6855 - ETA: 1:55 - 182ms/step
step 4380/5005 [=========================>....] - loss: 1.6053 - acc_top1: 0.4380 - acc_top5: 0.6857 - ETA: 1:53 - 182ms/step
step 4390/5005 [=========================>....] - loss: 2.2448 - acc_top1: 0.4381 - acc_top5: 0.6858 - ETA: 1:51 - 182ms/step
step 4400/5005 [=========================>....] - loss: 2.1593 - acc_top1: 0.4383 - acc_top5: 0.6860 - ETA: 1:50 - 182ms/step
step 4410/5005 [=========================>....] - loss: 2.2510 - acc_top1: 0.4384 - acc_top5: 0.6861 - ETA: 1:48 - 182ms/step
step 4420/5005 [=========================>....] - loss: 2.3358 - acc_top1: 0.4386 - acc_top5: 0.6863 - ETA: 1:46 - 182ms/step
step 4430/5005 [=========================>....] - loss: 1.8975 - acc_top1: 0.4388 - acc_top5: 0.6865 - ETA: 1:44 - 182ms/step
step 4440/5005 [=========================>....] - loss: 2.2592 - acc_top1: 0.4390 - acc_top5: 0.6866 - ETA: 1:42 - 182ms/step
step 4450/5005 [=========================>....] - loss: 2.4305 - acc_top1: 0.4392 - acc_top5: 0.6868 - ETA: 1:40 - 182ms/step
step 4460/5005 [=========================>....] - loss: 2.2147 - acc_top1: 0.4394 - acc_top5: 0.6870 - ETA: 1:39 - 182ms/step
step 4470/5005 [=========================>....] - loss: 2.1283 - acc_top1: 0.4395 - acc_top5: 0.6871 - ETA: 1:37 - 182ms/step
step 4480/5005 [=========================>....] - loss: 2.3747 - acc_top1: 0.4397 - acc_top5: 0.6873 - ETA: 1:35 - 182ms/step
step 4490/5005 [=========================>....] - loss: 2.1828 - acc_top1: 0.4398 - acc_top5: 0.6874 - ETA: 1:33 - 182ms/step
step 4500/5005 [=========================>....] - loss: 2.0526 - acc_top1: 0.4399 - acc_top5: 0.6875 - ETA: 1:31 - 182ms/step
step 4510/5005 [==========================>...] - loss: 2.3236 - acc_top1: 0.4401 - acc_top5: 0.6877 - ETA: 1:29 - 182ms/step
step 4520/5005 [==========================>...] - loss: 2.2861 - acc_top1: 0.4402 - acc_top5: 0.6877 - ETA: 1:28 - 182ms/step
step 4530/5005 [==========================>...] - loss: 1.8428 - acc_top1: 0.4402 - acc_top5: 0.6878 - ETA: 1:26 - 182ms/step
step 4540/5005 [==========================>...] - loss: 2.0070 - acc_top1: 0.4403 - acc_top5: 0.6879 - ETA: 1:24 - 182ms/step
step 4550/5005 [==========================>...] - loss: 2.1915 - acc_top1: 0.4404 - acc_top5: 0.6880 - ETA: 1:22 - 182ms/step
step 4560/5005 [==========================>...] - loss: 3.0099 - acc_top1: 0.4405 - acc_top5: 0.6881 - ETA: 1:20 - 182ms/step
step 4570/5005 [==========================>...] - loss: 2.6766 - acc_top1: 0.4406 - acc_top5: 0.6882 - ETA: 1:19 - 182ms/step
step 4580/5005 [==========================>...] - loss: 1.9979 - acc_top1: 0.4407 - acc_top5: 0.6884 - ETA: 1:17 - 182ms/step
step 4590/5005 [==========================>...] - loss: 2.2694 - acc_top1: 0.4408 - acc_top5: 0.6885 - ETA: 1:15 - 182ms/step
step 4600/5005 [==========================>...] - loss: 2.0960 - acc_top1: 0.4410 - acc_top5: 0.6886 - ETA: 1:13 - 182ms/step
step 4610/5005 [==========================>...] - loss: 1.7647 - acc_top1: 0.4412 - acc_top5: 0.6888 - ETA: 1:11 - 182ms/step
step 4620/5005 [==========================>...] - loss: 2.2624 - acc_top1: 0.4413 - acc_top5: 0.6890 - ETA: 1:09 - 182ms/step
step 4630/5005 [==========================>...] - loss: 2.2183 - acc_top1: 0.4415 - acc_top5: 0.6891 - ETA: 1:08 - 182ms/step
step 4640/5005 [==========================>...] - loss: 2.4054 - acc_top1: 0.4416 - acc_top5: 0.6893 - ETA: 1:06 - 182ms/step
step 4650/5005 [==========================>...] - loss: 2.3136 - acc_top1: 0.4418 - acc_top5: 0.6894 - ETA: 1:04 - 182ms/step
step 4660/5005 [==========================>...] - loss: 2.0141 - acc_top1: 0.4419 - acc_top5: 0.6896 - ETA: 1:02 - 182ms/step
step 4670/5005 [==========================>...] - loss: 2.3172 - acc_top1: 0.4421 - acc_top5: 0.6897 - ETA: 1:00 - 182ms/step
step 4680/5005 [===========================>..] - loss: 2.2701 - acc_top1: 0.4423 - acc_top5: 0.6899 - ETA: 59s - 182ms/step 
step 4690/5005 [===========================>..] - loss: 2.3217 - acc_top1: 0.4424 - acc_top5: 0.6900 - ETA: 57s - 182ms/step
step 4700/5005 [===========================>..] - loss: 2.3157 - acc_top1: 0.4425 - acc_top5: 0.6901 - ETA: 55s - 182ms/step
step 4710/5005 [===========================>..] - loss: 2.6235 - acc_top1: 0.4427 - acc_top5: 0.6903 - ETA: 53s - 182ms/step
step 4720/5005 [===========================>..] - loss: 1.9081 - acc_top1: 0.4428 - acc_top5: 0.6904 - ETA: 51s - 182ms/step
step 4730/5005 [===========================>..] - loss: 2.0469 - acc_top1: 0.4429 - acc_top5: 0.6905 - ETA: 50s - 182ms/step
step 4740/5005 [===========================>..] - loss: 1.8097 - acc_top1: 0.4429 - acc_top5: 0.6906 - ETA: 48s - 182ms/step
step 4750/5005 [===========================>..] - loss: 2.2513 - acc_top1: 0.4431 - acc_top5: 0.6907 - ETA: 46s - 182ms/step
step 4760/5005 [===========================>..] - loss: 1.8085 - acc_top1: 0.4433 - acc_top5: 0.6909 - ETA: 44s - 182ms/step
step 4770/5005 [===========================>..] - loss: 2.6079 - acc_top1: 0.4434 - acc_top5: 0.6910 - ETA: 42s - 182ms/step
step 4780/5005 [===========================>..] - loss: 2.5015 - acc_top1: 0.4434 - acc_top5: 0.6911 - ETA: 40s - 182ms/step
step 4790/5005 [===========================>..] - loss: 2.2674 - acc_top1: 0.4435 - acc_top5: 0.6912 - ETA: 39s - 182ms/step
step 4800/5005 [===========================>..] - loss: 2.4186 - acc_top1: 0.4436 - acc_top5: 0.6913 - ETA: 37s - 182ms/step
step 4810/5005 [===========================>..] - loss: 2.4752 - acc_top1: 0.4436 - acc_top5: 0.6913 - ETA: 35s - 182ms/step
INFO 2021-02-03 03:32:43,125 launch_utils.py:307] terminate all the procs
ERROR 2021-02-03 03:32:43,133 launch_utils.py:545] ABORT!!! Out of all 4 trainers, the trainer process with rank=[2] was aborted. Please check its log.
INFO 2021-02-03 03:32:46,135 launch_utils.py:307] terminate all the procs
step 4820/5005 [===========================>..] - loss: 1.6138 - acc_top1: 0.4437 - acc_top5: 0.6915 - ETA: 33s - 182ms/step
step 4830/5005 [===========================>..] - loss: 2.0879 - acc_top1: 0.4439 - acc_top5: 0.6916 - ETA: 31s - 182ms/step
step 4840/5005 [============================>.] - loss: 2.1731 - acc_top1: 0.4439 - acc_top5: 0.6917 - ETA: 30s - 182ms/step
step 4850/5005 [============================>.] - loss: 2.0019 - acc_top1: 0.4440 - acc_top5: 0.6918 - ETA: 28s - 182ms/step
step 4860/5005 [============================>.] - loss: 2.0142 - acc_top1: 0.4442 - acc_top5: 0.6920 - ETA: 26s - 182ms/step
step 4870/5005 [============================>.] - loss: 2.3405 - acc_top1: 0.4443 - acc_top5: 0.6920 - ETA: 24s - 182ms/step
step 4880/5005 [============================>.] - loss: 1.9618 - acc_top1: 0.4445 - acc_top5: 0.6922 - ETA: 22s - 182ms/step
step 4890/5005 [============================>.] - loss: 2.5878 - acc_top1: 0.4446 - acc_top5: 0.6923 - ETA: 20s - 182ms/step
step 4900/5005 [============================>.] - loss: 2.4356 - acc_top1: 0.4447 - acc_top5: 0.6923 - ETA: 19s - 182ms/step
step 4910/5005 [============================>.] - loss: 2.0725 - acc_top1: 0.4447 - acc_top5: 0.6924 - ETA: 17s - 182ms/step
step 4920/5005 [============================>.] - loss: 2.4625 - acc_top1: 0.4448 - acc_top5: 0.6925 - ETA: 15s - 182ms/step
step 4930/5005 [============================>.] - loss: 2.4038 - acc_top1: 0.4449 - acc_top5: 0.6926 - ETA: 13s - 182ms/step
step 4940/5005 [============================>.] - loss: 2.4866 - acc_top1: 0.4451 - acc_top5: 0.6927 - ETA: 11s - 182ms/step
step 4950/5005 [============================>.] - loss: 2.2683 - acc_top1: 0.4452 - acc_top5: 0.6928 - ETA: 10s - 182ms/step
step 4960/5005 [============================>.] - loss: 2.0255 - acc_top1: 0.4453 - acc_top5: 0.6929 - ETA: 8s - 182ms/step 
step 4970/5005 [============================>.] - loss: 2.0075 - acc_top1: 0.4455 - acc_top5: 0.6930 - ETA: 6s - 182ms/step
step 4980/5005 [============================>.] - loss: 2.0211 - acc_top1: 0.4456 - acc_top5: 0.6932 - ETA: 4s - 182ms/step
step 4990/5005 [============================>.] - loss: 2.1345 - acc_top1: 0.4457 - acc_top5: 0.6933 - ETA: 2s - 182ms/step
step 5000/5005 [============================>.] - loss: 2.1437 - acc_top1: 0.4458 - acc_top5: 0.6934 - ETA: 0s - 182ms/step
step 5005/5005 [==============================] - loss: 2.0431 - acc_top1: 0.4459 - acc_top5: 0.6934 - 184ms/step          
save checkpoint at /root/hrank/PaddleSlim/demo/dygraph/pruning/hrank_resnet34_025_120_models/0
Eval begin...
Traceback (most recent call last):
  File "new_train.py", line 201, in <module>
    main()
  File "new_train.py", line 197, in main
    compress(args)
  File "new_train.py", line 190, in compress
    num_workers=8)
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 1506, in fit
    eval_logs = self._run_one_epoch(eval_loader, cbks, 'eval')
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 1802, in _run_one_epoch
    data[len(self._inputs):])
  File "</usr/local/lib/python3.7/site-packages/decorator.py:decorator-gen-223>", line 2, in eval_batch
  File "/usr/local/lib/python3.7/site-packages/paddle/fluid/dygraph/base.py", line 315, in _decorate_function
    return func(*args, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 993, in eval_batch
    loss = self._adapter.eval_batch(inputs, labels)
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 689, in eval_batch
    outputs = [_all_gather(o, self._nranks) for o in to_list(outputs)]
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 689, in <listcomp>
    outputs = [_all_gather(o, self._nranks) for o in to_list(outputs)]
  File "/usr/local/lib/python3.7/site-packages/paddle/hapi/model.py", line 107, in _all_gather
    x, nranks, ring_id=ring_id, use_calc_stream=use_calc_stream)
  File "/usr/local/lib/python3.7/site-packages/paddle/fluid/layers/collective.py", line 128, in _c_allgather
    'use_calc_stream': use_calc_stream
  File "/usr/local/lib/python3.7/site-packages/paddle/fluid/layer_helper.py", line 43, in append_op
    return self.main_program.current_block().append_op(*args, **kwargs)
  File "/usr/local/lib/python3.7/site-packages/paddle/fluid/framework.py", line 3013, in append_op
    kwargs.get("stop_gradient", False))
  File "/usr/local/lib/python3.7/site-packages/paddle/fluid/dygraph/tracer.py", line 45, in trace_op
    not stop_gradient)
RuntimeError: (NotFound) Operator (c_allgather) is not registered.
  [Hint: op_info_ptr should not be null.] (at /root/slim_develop/Paddle/paddle/fluid/framework/op_info.h:151)

