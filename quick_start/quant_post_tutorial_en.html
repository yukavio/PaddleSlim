

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Post-training Quantization of image classification model - quick start &mdash; PaddleSlim 1.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="PaddleSlim 1.0 documentation" href="../index.html"/>
        <link rel="up" title="Quick Start" href="index_en.html"/>
        <link rel="next" title="Aadvanced Tutorials" href="../tutorials/index_en.html"/>
        <link rel="prev" title="Training-aware Quantization of image classification model - quick start" href="quant_aware_tutorial_en.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index_en.html" class="icon icon-home"> PaddleSlim
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">中文文档</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intro_en.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install_en.html">Install</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index_en.html">Quick Start</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="pruning_tutorial_en.html">Channel Pruning for Image Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="nas_tutorial_en.html">Nerual Architecture Search for Image Classification</a></li>
<li class="toctree-l2"><a class="reference internal" href="quant_aware_tutorial_en.html">Training-aware Quantization of image classification model - quick start</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Post-training Quantization of image classification model - quick start</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#necessary-imports">1. Necessary imports</a></li>
<li class="toctree-l3"><a class="reference internal" href="#model-architecture">2. Model architecture</a></li>
<li class="toctree-l3"><a class="reference internal" href="#train-normal-model">3. Train normal model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#input-data-definition">3.1 input data definition</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-model-and-testing">3.2 training model and testing</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#post-training-quantization">4. Post training quantization</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/index_en.html">Aadvanced Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api_en/index_en.html">API Documents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../model_zoo_en.html">Model Zoo</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index_en.html">PaddleSlim</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index_en.html">Docs</a> &raquo;</li>
      
          <li><a href="index_en.html">Quick Start</a> &raquo;</li>
      
    <li>Post-training Quantization of image classification model - quick start</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/quick_start/quant_post_tutorial_en.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="post-training-quantization-of-image-classification-model-quick-start">
<h1>Post-training Quantization of image classification model - quick start<a class="headerlink" href="#post-training-quantization-of-image-classification-model-quick-start" title="Permalink to this headline">¶</a></h1>
<p>This tutorial shows how to do post training quantization using <a class="reference external" href="https://paddlepaddle.github.io/PaddleSlim/api_en/paddleslim.quant.html#paddleslim.quant.quanter.quant_post">API</a> in PaddleSlim. We use MobileNetV1 to train image classification model as example. The tutorial contains follow sections:</p>
<ol class="arabic simple">
<li>Necessary imports</li>
<li>Model architecture</li>
<li>Train normal model</li>
<li>Post training quantization</li>
</ol>
<div class="section" id="necessary-imports">
<h2>1. Necessary imports<a class="headerlink" href="#necessary-imports" title="Permalink to this headline">¶</a></h2>
<p>PaddleSlim depends on Paddle1.7. Please make true that you have installed Paddle correctly. Then do the necessary imports:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">paddle</span>
<span class="kn">import</span> <span class="nn">paddle.fluid</span> <span class="k">as</span> <span class="nn">fluid</span>
<span class="kn">import</span> <span class="nn">paddleslim</span> <span class="k">as</span> <span class="nn">slim</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
<div class="section" id="model-architecture">
<h2>2. Model architecture<a class="headerlink" href="#model-architecture" title="Permalink to this headline">¶</a></h2>
<p>The section constructs a classification model, which use <code class="docutils literal"><span class="pre">MobileNetV1</span></code> and MNIST dataset. The model&#8217;s input size is <code class="docutils literal"><span class="pre">[1,</span> <span class="pre">28,</span> <span class="pre">28]</span></code> and output size is 10. In order to show tutorial conveniently, we pre-defined a method to get image classification model in <code class="docutils literal"><span class="pre">paddleslim.models</span></code>.</p>
<blockquote>
<div>note: The APIs in <code class="docutils literal"><span class="pre">paddleslim.models</span></code> are not formal inferface in PaddleSlim. They are defined to simplify the tutorial such as the definition of model structure and the construction of Program.</div></blockquote>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">exe</span><span class="p">,</span> <span class="n">train_program</span><span class="p">,</span> <span class="n">val_program</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span> <span class="o">=</span> \
    <span class="n">slim</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">image_classification</span><span class="p">(</span><span class="s2">&quot;MobileNet&quot;</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">],</span> <span class="mi">10</span><span class="p">,</span> <span class="n">use_gpu</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="train-normal-model">
<h2>3. Train normal model<a class="headerlink" href="#train-normal-model" title="Permalink to this headline">¶</a></h2>
<p>The section shows how to define model inputs, train and test model. The reason for training the normal image classification model first is that the post training quantization is performed on the well-trained model.</p>
<div class="section" id="input-data-definition">
<h3>3.1 input data definition<a class="headerlink" href="#input-data-definition" title="Permalink to this headline">¶</a></h3>
<p>To speed up training process, we select MNIST dataset to train image classification model. The API <code class="docutils literal"><span class="pre">paddle.dataset.mnist</span></code> in Paddle framework contains downloading and reading the images in dataset.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">paddle.dataset.mnist</span> <span class="k">as</span> <span class="nn">reader</span>
<span class="n">train_reader</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
        <span class="n">reader</span><span class="o">.</span><span class="n">train</span><span class="p">(),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">test_reader</span> <span class="o">=</span> <span class="n">paddle</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span>
        <span class="n">reader</span><span class="o">.</span><span class="n">train</span><span class="p">(),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">train_feeder</span> <span class="o">=</span> <span class="n">fluid</span><span class="o">.</span><span class="n">DataFeeder</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">fluid</span><span class="o">.</span><span class="n">CPUPlace</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="section" id="training-model-and-testing">
<h3>3.2 training model and testing<a class="headerlink" href="#training-model-and-testing" title="Permalink to this headline">¶</a></h3>
<p>Define functions to train and test model. We only need call the functions when formal model training and quantization model training. The function does one epoch training because that MNIST dataset is small and top1 accuracy will reach 95% after one epoch.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">prog</span><span class="p">):</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_reader</span><span class="p">():</span>
        <span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">exe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">feed</span><span class="o">=</span><span class="n">train_feeder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">fetch_list</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">acc1</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">acc5</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">test</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">outputs</span><span class="o">=</span><span class="n">outputs</span><span class="p">):</span>
    <span class="nb">iter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">[[],</span> <span class="p">[]]</span>
    <span class="k">for</span> <span class="n">data</span> <span class="ow">in</span> <span class="n">train_reader</span><span class="p">():</span>
        <span class="n">acc1</span><span class="p">,</span> <span class="n">acc5</span><span class="p">,</span> <span class="n">loss</span> <span class="o">=</span> <span class="n">exe</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">prog</span><span class="p">,</span> <span class="n">feed</span><span class="o">=</span><span class="n">train_feeder</span><span class="o">.</span><span class="n">feed</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">fetch_list</span><span class="o">=</span><span class="n">outputs</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">iter</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;test&#39;</span><span class="p">,</span> <span class="n">acc1</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">acc5</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">loss</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc1</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">acc5</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
        <span class="nb">iter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;final test result&#39;</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">res</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">mean</span><span class="p">())</span>
</pre></div>
</div>
<p>Call <code class="docutils literal"><span class="pre">train</span></code> function to train normal classification model. <code class="docutils literal"><span class="pre">train_program</span></code> is defined in 2. Model architecture.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">train_program</span><span class="p">)</span>
</pre></div>
</div>
<p>Call <code class="docutils literal"><span class="pre">test</span></code> function to test normal classification model. <code class="docutils literal"><span class="pre">val_program</span></code> is defined in 2. Model architecture.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">test</span><span class="p">(</span><span class="n">val_program</span><span class="p">)</span>
</pre></div>
</div>
<p>Save inference model. Save well-trained model in <code class="docutils literal"><span class="pre">'./inference_model'</span></code>. We will load the model when doing post training quantization.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">target_vars</span> <span class="o">=</span> <span class="p">[</span><span class="n">val_program</span><span class="o">.</span><span class="n">global_block</span><span class="p">()</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">]</span>
<span class="n">fluid</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">save_inference_model</span><span class="p">(</span><span class="n">dirname</span><span class="o">=</span><span class="s1">&#39;./inference_model&#39;</span><span class="p">,</span>
        <span class="n">feeded_var_names</span><span class="o">=</span><span class="p">[</span><span class="n">var</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">],</span>
        <span class="n">target_vars</span><span class="o">=</span><span class="n">target_vars</span><span class="p">,</span>
        <span class="n">executor</span><span class="o">=</span><span class="n">exe</span><span class="p">,</span>
        <span class="n">main_program</span><span class="o">=</span><span class="n">val_program</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="post-training-quantization">
<h2>4. Post training quantization<a class="headerlink" href="#post-training-quantization" title="Permalink to this headline">¶</a></h2>
<p>Call <code class="docutils literal"><span class="pre">slim.quant.quant_post</span></code> API to do post training quantization. The API will load the inference model in <code class="docutils literal"><span class="pre">'./inference_model'</span></code> first and calibrate the quantization parameters using data in sample_generator. In this tutorial, we use 10 mini-batch data to calibrate the quantization parameters. There is no need to train model but run forward to get activations for quantization scales calculation. The model after post training quantization are saved in <code class="docutils literal"><span class="pre">'./quant_post_model'</span></code>.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">slim</span><span class="o">.</span><span class="n">quant</span><span class="o">.</span><span class="n">quant_post</span><span class="p">(</span>
        <span class="n">executor</span><span class="o">=</span><span class="n">exe</span><span class="p">,</span>
        <span class="n">model_dir</span><span class="o">=</span><span class="s1">&#39;./inference_model&#39;</span><span class="p">,</span>
        <span class="n">quantize_model_path</span><span class="o">=</span><span class="s1">&#39;./quant_post_model&#39;</span><span class="p">,</span>
        <span class="n">sample_generator</span><span class="o">=</span><span class="n">reader</span><span class="o">.</span><span class="n">test</span><span class="p">(),</span>
        <span class="n">batch_nums</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</pre></div>
</div>
<p>Load the model after post training quantization in <code class="docutils literal"><span class="pre">'./quant_post_model'</span></code> and run <code class="docutils literal"><span class="pre">test</span></code> function. The top1 and top5 accuracy are close to result in <code class="docutils literal"><span class="pre">3.2</span> <span class="pre">training</span> <span class="pre">model</span> <span class="pre">and</span> <span class="pre">testing</span></code>. We preform the post training quantization without loss on this image classification model.</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">quant_post_prog</span><span class="p">,</span> <span class="n">feed_target_names</span><span class="p">,</span> <span class="n">fetch_targets</span> <span class="o">=</span> <span class="n">fluid</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">load_inference_model</span><span class="p">(</span>
        <span class="n">dirname</span><span class="o">=</span><span class="s1">&#39;./quant_post_model&#39;</span><span class="p">,</span>
        <span class="n">executor</span><span class="o">=</span><span class="n">exe</span><span class="p">)</span>
<span class="n">test</span><span class="p">(</span><span class="n">quant_post_prog</span><span class="p">,</span> <span class="n">fetch_targets</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../tutorials/index_en.html" class="btn btn-neutral float-right" title="Aadvanced Tutorials" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="quant_aware_tutorial_en.html" class="btn btn-neutral" title="Training-aware Quantization of image classification model - quick start" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, paddleslim.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'1.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>